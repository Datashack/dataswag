{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ClusteringTrainKM.py\n"
     ]
    }
   ],
   "source": [
    "%%file ClusteringTrainKM.py\n",
    "\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class ClusteringKM:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, train_path, save_path):\n",
    "        self.train_path = train_path\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    '''#Helper Function to get images from train path\n",
    "    def get_train_images(self, user_list):\n",
    "        list_users = user_list\n",
    "        self.train_imgs = {}\n",
    "        for i in list_users:\n",
    "            temp_path = self.train_path + i\n",
    "            for j in glob.glob(temp_path + '/*.jpg'):\n",
    "                file_name = j.replace(temp_path,'')[1:]\n",
    "                img = io.imread(j)\n",
    "                self.train_imgs[(i,file_name)] = img \n",
    "        print(\"Number of images loaded:\", len(self.train_imgs))'''\n",
    "\n",
    "    def get_train_images(self, train_path, user_list):\n",
    "        #list_users = user_list\n",
    "        self.train_imgs = {}\n",
    "        print(len(user_list))\n",
    "        for i in user_list:\n",
    "            file_name = i\n",
    "            img = io.imread(train_path+str(i)+'.jpg')\n",
    "            print(train_path+str(i)+'.jpg')\n",
    "            self.train_imgs[(i,file_name)] = img \n",
    "        print(\"Number of images loaded:\", len(self.train_imgs))\n",
    "\n",
    "    \n",
    "    #Helper function to convert image to d-dimension vector for each image and \n",
    "    #return dataframe of all images\n",
    "    def convert_to_features(self, columns):\n",
    "        features = []\n",
    "        for i in self.train_imgs.items():\n",
    "            r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "            g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "            b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "            canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "            try:\n",
    "                orb = cv2.ORB_create(100)\n",
    "                kp = orb.detect(i[1],None)\n",
    "                kp, des = orb.compute(i[1], kp)\n",
    "                orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "                orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "        df = pd.DataFrame(features, columns = columns)\n",
    "        return df\n",
    "    \n",
    "    def model_images_fit(self, df, k, extra_cols, rand_state):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "\n",
    "        #Implement Gaussian Mixture Model Algortihm \n",
    "        model = GaussianMixture(n_components=k, random_state=9001)\n",
    "\n",
    "        #Fit Model and Predict\n",
    "        model.fit(data)\n",
    "        y_pred = model.predict_proba(data)\n",
    "\n",
    "        #Add prediction to dataframe and return \n",
    "        for i in range(0,k+1):\n",
    "            if i==k:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = \"Prob_\" + str(i)\n",
    "            df[label] = y_pred[:,i]\n",
    "        return df, model\n",
    "    \n",
    "    def model_users_fit(self, df, k, extra_cols, rand_state):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "\n",
    "        #Implement K-Means Algortihm\n",
    "        model = KMeans(n_clusters=k, random_state=rand_state)\n",
    "\n",
    "        #Fit Model, Predict and Return\n",
    "        model.fit(data)\n",
    "        y_pred = model.predict(data)\n",
    "        df['Prediction'] = model.labels_\n",
    "        return df, model\n",
    "    \n",
    "    #Helper function to create folders for Image Clustering\n",
    "    def save_clusters(self, df, label):\n",
    "        self.save_path += label + \"/\"\n",
    "        for i in self.train_imgs.items():\n",
    "            temp_row = df[df[\"URL\"]==i[0][1]]\n",
    "            try:\n",
    "                name, pred_folder = i[0][1], str(temp_row['Prediction'].values[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            temp_path = self.save_path + \"Cluster\" + pred_folder + \"/\"\n",
    "            if not os.path.exists(temp_path):\n",
    "                os.makedirs(temp_path)\n",
    "            io.imsave(temp_path+name, i[1])\n",
    "        print(\"All Images Saved.\")\n",
    "            \n",
    "    #Helper function to obtain percentage of Cluster Presence\n",
    "    def get_cluster_presence(self, df, k):\n",
    "        cluster_presence = []\n",
    "        for i in list(df['User_Handle'].unique()):\n",
    "            user_dict = {}\n",
    "            temp_df = df[df['User_Handle']==i]\n",
    "            post_count  =  len(temp_df)\n",
    "            user_dict['User_Handle'] = i\n",
    "            for j in range(0, k):\n",
    "                user_dict[\"Cluster_\"+str(j)] = sum(temp_df['Prob_'+str(j)])/post_count\n",
    "            cluster_presence.append(user_dict)\n",
    "        df_presence = pd.DataFrame(cluster_presence)\n",
    "        df_presence = df_presence.fillna(0)\n",
    "        return df_presence\n",
    "    \n",
    "    #Helper function to save model \n",
    "    def save_model(self, model, path):\n",
    "        joblib.dump(model, path) \n",
    "        print(\"Model Saved.\")\n",
    "\n",
    "\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class Ranking:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, target_path):\n",
    "        self.target_path = target_path\n",
    "\n",
    "    #Helper Function to get images from target path \n",
    "    def get_images_target(self):\n",
    "        #Get all Images of Users in the List\n",
    "        self.target_imgs = {}\n",
    "        for j in glob.glob(self.target_path + '/*.jpg'):\n",
    "            file_name = j.replace(self.target_path,'')[:]\n",
    "            img = io.imread(j)\n",
    "            self.target_imgs[(\"Input/Target\",file_name)] = img\n",
    "        print(\"Number of images loaded:\", len(self.target_imgs))\n",
    "    \n",
    "    #Helper function to load saved model\n",
    "    def load_model(self, path):\n",
    "        model = joblib.load(path)\n",
    "        print (\"Model loaded.\")\n",
    "        return model\n",
    "\n",
    "    #Helper function to convert image to d-dimension vector for each image and \n",
    "    #return dataframe of all images\n",
    "    def convert_to_features(self, columns):\n",
    "        features = []\n",
    "        for i in self.target_imgs.items():\n",
    "            r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "            g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "            b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "            canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "            try:\n",
    "                orb = cv2.ORB_create(100)\n",
    "                kp = orb.detect(i[1],None)\n",
    "                kp, des = orb.compute(i[1], kp)\n",
    "                orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "                orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "        df = pd.DataFrame(features, columns = columns)\n",
    "        return df\n",
    "\n",
    "    #Helper function to make prediction for target images using image model\n",
    "    def predict(self, df, model, k, cluster_names, extra_cols):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "            \n",
    "        #Make Prediction\n",
    "        y_pred = model.predict_proba(data)\n",
    "        \n",
    "        #Add prediction to dataframe and return \n",
    "        for i in range(0,k+1):\n",
    "            if i==k:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = cluster_names[i] + \" (\" + str(i) + \")\"\n",
    "            df[label] = y_pred[:,i]\n",
    "        return df\n",
    "    \n",
    "    #Helper function to generate distance dictionary\n",
    "    def get_result(self, df, k, model):\n",
    "        final_dict = {}\n",
    "        for i in range(0,len(df)):\n",
    "            temp_file = df.iloc[i,1]\n",
    "            temp_dist = []\n",
    "            for j in range(0, k):\n",
    "                temp_dist.append(np.linalg.norm(df.iloc[i,14:14+k].astype(float)-model.cluster_centers_[j]))\n",
    "            final_dict[temp_file] = temp_dist\n",
    "        return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
      "  warn('Viewer requires Qt')\n"
     ]
    }
   ],
   "source": [
    "import cv2 ## issues \n",
    "import skimage\n",
    "from skimage import io\n",
    "import pickle\n",
    "#define File-Path to Users Folder\n",
    "#import scikit-image\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "#img = io.imread('~/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/11117159_1591691794419786_1496739027_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/1.jpg\n",
      "/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/2.jpg\n",
      "/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/3.jpg\n",
      "Number of images loaded: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import ClusteringTrainKM\n",
    "\n",
    "train_path = '/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/'\n",
    "save_path = '/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/'\n",
    "dest_img =  '/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/'\n",
    "userlist= [1,2,3]\n",
    "#user list will be the picture number! \n",
    "\n",
    "#Helper Function to get images from train path\n",
    "\n",
    "\n",
    "c = ClusteringTrainKM.ClusteringKM(train_path, save_path )\n",
    "c.get_train_images(train_path, user_list = ['1','2','3'])\n",
    "#Create Object\n",
    "\n",
    "\n",
    "#obj_train = ClusteringTrain.Clustering(train_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Handle</th>\n",
       "      <th>URL</th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0129197103678</td>\n",
       "      <td>87.63115693479644</td>\n",
       "      <td>153.0</td>\n",
       "      <td>115.81277500106796</td>\n",
       "      <td>85.89295297982054</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.67071158528771</td>\n",
       "      <td>67.8223132968387</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.53199891067538</td>\n",
       "      <td>146.9227747599284</td>\n",
       "      <td>130.7175958633423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>182.62494660173437</td>\n",
       "      <td>71.07541423145153</td>\n",
       "      <td>214.0</td>\n",
       "      <td>114.09603945063864</td>\n",
       "      <td>61.1908801925312</td>\n",
       "      <td>116.0</td>\n",
       "      <td>59.164076850783886</td>\n",
       "      <td>49.102368231584244</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.82652505446623</td>\n",
       "      <td>158.0485753377279</td>\n",
       "      <td>124.39350624084474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>224.64943771626298</td>\n",
       "      <td>37.1131291445464</td>\n",
       "      <td>242.0</td>\n",
       "      <td>177.51967726088256</td>\n",
       "      <td>68.5927534247089</td>\n",
       "      <td>184.0</td>\n",
       "      <td>103.62004998077663</td>\n",
       "      <td>101.47531061170602</td>\n",
       "      <td>66.0</td>\n",
       "      <td>22.367919389978212</td>\n",
       "      <td>127.65924498240155</td>\n",
       "      <td>189.51394405364988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User_Handle URL              R_Mean              R_STD  R_MED  \\\n",
       "0           1   1   135.0129197103678  87.63115693479644  153.0   \n",
       "1           2   2  182.62494660173437  71.07541423145153  214.0   \n",
       "2           3   3  224.64943771626298   37.1131291445464  242.0   \n",
       "\n",
       "               G_Mean              G_STD  G_MED              B_Mean  \\\n",
       "0  115.81277500106796  85.89295297982054  109.0   58.67071158528771   \n",
       "1  114.09603945063864   61.1908801925312  116.0  59.164076850783886   \n",
       "2  177.51967726088256   68.5927534247089  184.0  103.62004998077663   \n",
       "\n",
       "                B_STD B_MED               Canny               ORB_X  \\\n",
       "0    67.8223132968387  33.0   22.53199891067538   146.9227747599284   \n",
       "1  49.102368231584244  42.0   15.82652505446623   158.0485753377279   \n",
       "2  101.47531061170602  66.0  22.367919389978212  127.65924498240155   \n",
       "\n",
       "                ORB_Y  \n",
       "0   130.7175958633423  \n",
       "1  124.39350624084474  \n",
       "2  189.51394405364988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get train dataframe\n",
    "train_df_cols = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "\n",
    "train_df = c.convert_to_features(train_df_cols)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "model = joblib.load('model_images.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
