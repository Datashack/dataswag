{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
      "  warn('Viewer requires Qt')\n",
      "/anaconda/envs/python3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import re\n",
    "from scipy import stats\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "import subprocess\n",
    "import time\n",
    "import statsmodels.regression.linear_model as sm\n",
    "from statsmodels.api import OLS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from RecSystemKM import RecSystemKM_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "path = '/Users/kimia/Desktop/Capstone/hotel/Rec_system/'\n",
    "df = pd.read_csv(path+'users_followers_merged.csv')\n",
    "\n",
    "### pull a sample for the pipeline\n",
    "df = df[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape pics from users - don't rerun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for i, v in enumerate(df.username): \n",
    "    time.sleep(20)\n",
    "    subprocess.check_output([\"instaloader\", (str(v))])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the Engagment pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "temp_path = '/Users/kimia/Desktop/Capstone/hotel/Rec_system/User_pics/All/'\n",
    "train_path = '/Users/kimia/Desktop/Capstone/hotel/Rec_system/User_pics/All/'\n",
    "save_path = '/Users/kimia/Desktop/Capstone/hotel/Rec_system/User_pics/All/'\n",
    "dest_img =  '/Users/kimia/Desktop/Capstone/hotel/Rec_system/User_pics/All/'\n",
    "\n",
    "userlist= ['or_shmul','fathy_abo_dahis', 'iamkurdapya', 'abhishekraghav015',  'jnbax']\n",
    "#user list will be the picture number! \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 302\n"
     ]
    }
   ],
   "source": [
    "c = RecSystemKM_test(train_path, save_path )\n",
    "c.Karans_get_train_images(userlist)\n",
    "\n",
    "\n",
    "#Create Object\n",
    "\n",
    "train_df = c.convert_to_features(columns = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now merge with # of followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/kimia/Desktop/Capstone/hotel/Rec_system/'\n",
    "df_usernames = pd.read_csv(path+'users_followers_merged.csv')\n",
    "df_usernames['User_Handle'] = df_usernames.username\n",
    "\n",
    "#df_usernames['followers'] = (df_usernames['followers'].apply(lambda x: x.replace('k',\"000\").replace(\".\",\"\").replace(\"m\",\"000000\").replace(\",\",\"\")))\n",
    "#df_usernames.followers = pd.to_numeric(df_usernames.followers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Engagement_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%file Engagement_pipeline.py\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "class Engagement:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, train_path, save_path):\n",
    "        self.train_path = train_path\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    def zscore(x,mu,std):\n",
    "        zscore = (x-mu)/std\n",
    "        return(zscore)\n",
    "\n",
    "    def metrics(self, df): \n",
    "        df[['likes_count','followers']] = df[['likes_count','followers']].apply(pd.to_numeric)\n",
    "\n",
    "        df['likes_score'] = (df['likes_count'])/(df['followers'])\n",
    "\n",
    "        df['comments_score'] = (df['comment_count'])/(df['followers'])\n",
    "\n",
    "        df['zscore_likes'] = zscore(df['likes_score'], df.likes_score.std(), df.likes_score.mean())\n",
    "\n",
    "        df['zscore_comments'] = zscore(df['comments_score'], df.comments_score.std(), df.comments_score.mean())\n",
    "\n",
    "        df['final_score'] = df['zscore_likes'] + df['zscore_comments']\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    def prep_model(self, df, columns_to_remove): \n",
    "    \n",
    "        df = df.drop(columns_to_remove, axis = 1, inplace = True)\n",
    "        \n",
    "        rands = np.random.seed(9001)\n",
    "        msk = np.random.rand(len(df)) < 0.25\n",
    "        data_train = df[~msk]\n",
    "        data_test = df[msk]\n",
    "        \n",
    "        y_train = data_train.final_score\n",
    "        y_test = data_test.final_score\n",
    "\n",
    "        predictors = ['R_Mean', 'R_STD', 'R_MED', 'G_Mean', 'G_STD', 'G_MED', 'B_Mean',\n",
    "               'B_STD', 'B_MED', 'Canny', 'ORB_X', 'ORB_Y',]\n",
    "        X_train = data_train[predictors]\n",
    "        X_test = data_test[predictors]\n",
    "        \n",
    "        return y_train, y_text, X_train, X_test ### should these be self?\n",
    "        \n",
    "    def linear(): ## yes those should be self if this is to run automatically\n",
    "        \n",
    "        lm = linear_model.LinearRegression() \n",
    "        model = lm.fit(X_train,y_train) \n",
    "        predictions = lm.predict(X_train)\n",
    "\n",
    "        model.score(X_train,y_train), model.score(X_test,y_test)\n",
    "        \n",
    "    def Ridge():\n",
    "        alpha= [10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2,10**3, ]\n",
    "        ridge = RidgeCV(alphas=alpha, cv=10, fit_intercept=True)\n",
    "        ridge.fit(X_train, y_train)\n",
    "        \n",
    "        train_score = ridge.score(X_train, y_train)\n",
    "        test_score = ridge.score(X_test, y_test)\n",
    "        return(train_score, test_score)\n",
    "\n",
    "\n",
    "\n",
    "    def Lasso():\n",
    "        alpha= [10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2,10**3, ]\n",
    "        lasso = LassoCV(alphas=alpha, cv=10, max_iter=10000, fit_intercept=True)\n",
    "        lasso.fit(X_train, y_train)\n",
    "        \n",
    "        train_score = lasso.score(X_train, y_train)\n",
    "        test_score = lasso.score(X_test, y_test)\n",
    "        \n",
    "        return(train_score, test_score)\n",
    "\n",
    "        \n",
    "        ### I also did Poly Feats but seems poor choice here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def zscore(x,mu,std):\n",
    "    zscore = (x-mu)/std\n",
    "    return(zscore)\n",
    "\n",
    "def metrics(df): \n",
    "    df[['likes_count','followers']] = df[['likes_count','followers']].apply(pd.to_numeric)\n",
    "\n",
    "    df['likes_score'] = (df['likes_count'])/(df['followers'])\n",
    "    \n",
    "    df['comments_score'] = (df['comment_count'])/(df['followers'])\n",
    "    \n",
    "    df['zscore_likes'] = zscore(df['likes_score'], df.likes_score.std(), df.likes_score.mean())\n",
    "    \n",
    "    df['zscore_comments'] = zscore(df['comments_score'], df.comments_score.std(), df.comments_score.mean())\n",
    "    \n",
    "    df['final_score'] = df['zscore_likes'] + df['zscore_comments']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_usernames = df_usernames[0:5]\n",
    "metrics(df_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>138.5661978298945</td>\n",
       "      <td>68.85854358506768</td>\n",
       "      <td>168.0</td>\n",
       "      <td>133.85562977914478</td>\n",
       "      <td>84.97953749629683</td>\n",
       "      <td>167.0</td>\n",
       "      <td>135.93238711606648</td>\n",
       "      <td>68.48064869294063</td>\n",
       "      <td>155.0</td>\n",
       "      <td>14.965277777777779</td>\n",
       "      <td>127.16971705754598</td>\n",
       "      <td>125.47407576243084</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134.14220225127087</td>\n",
       "      <td>39.89299878365912</td>\n",
       "      <td>136.0</td>\n",
       "      <td>136.18835437225</td>\n",
       "      <td>42.46455028864543</td>\n",
       "      <td>145.0</td>\n",
       "      <td>139.70720662992866</td>\n",
       "      <td>47.352066977158835</td>\n",
       "      <td>152.0</td>\n",
       "      <td>8.80923202614379</td>\n",
       "      <td>183.53733704884849</td>\n",
       "      <td>61.022005335489915</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.1995119398522</td>\n",
       "      <td>51.268360928596465</td>\n",
       "      <td>165.0</td>\n",
       "      <td>153.80132374300482</td>\n",
       "      <td>54.62034510182328</td>\n",
       "      <td>165.0</td>\n",
       "      <td>155.4477337776069</td>\n",
       "      <td>57.38931896695739</td>\n",
       "      <td>168.0</td>\n",
       "      <td>10.103485838779957</td>\n",
       "      <td>152.41735134124758</td>\n",
       "      <td>110.90057148933411</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>143.861954803708</td>\n",
       "      <td>43.83359910090871</td>\n",
       "      <td>157.0</td>\n",
       "      <td>144.2480135845188</td>\n",
       "      <td>43.783710809740576</td>\n",
       "      <td>158.0</td>\n",
       "      <td>142.78141953949336</td>\n",
       "      <td>41.879963576873514</td>\n",
       "      <td>155.0</td>\n",
       "      <td>12.883986928104575</td>\n",
       "      <td>91.61554183959959</td>\n",
       "      <td>72.7517301559448</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>152.3564599609375</td>\n",
       "      <td>71.13307536516064</td>\n",
       "      <td>172.0</td>\n",
       "      <td>136.37180419921876</td>\n",
       "      <td>81.45707132690796</td>\n",
       "      <td>150.0</td>\n",
       "      <td>129.059794921875</td>\n",
       "      <td>58.861371280828195</td>\n",
       "      <td>135.0</td>\n",
       "      <td>18.70103759765625</td>\n",
       "      <td>119.66093983769417</td>\n",
       "      <td>120.46904077291488</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>169.93778076171876</td>\n",
       "      <td>55.94774983219537</td>\n",
       "      <td>195.0</td>\n",
       "      <td>162.66536865234374</td>\n",
       "      <td>60.42389665519665</td>\n",
       "      <td>187.0</td>\n",
       "      <td>147.715810546875</td>\n",
       "      <td>50.294297687803734</td>\n",
       "      <td>172.0</td>\n",
       "      <td>13.404931640625</td>\n",
       "      <td>121.81377463102342</td>\n",
       "      <td>103.98939337313175</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>114.598359375</td>\n",
       "      <td>62.32804919182335</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.28396484375</td>\n",
       "      <td>64.98113367053654</td>\n",
       "      <td>71.0</td>\n",
       "      <td>83.50236083984375</td>\n",
       "      <td>64.24198400637135</td>\n",
       "      <td>62.0</td>\n",
       "      <td>14.2304443359375</td>\n",
       "      <td>116.57670060396194</td>\n",
       "      <td>119.93656636208296</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>164.6656982421875</td>\n",
       "      <td>68.48715507526556</td>\n",
       "      <td>190.0</td>\n",
       "      <td>138.269208984375</td>\n",
       "      <td>78.75741397490727</td>\n",
       "      <td>150.0</td>\n",
       "      <td>128.38324462890625</td>\n",
       "      <td>63.41391742252502</td>\n",
       "      <td>124.0</td>\n",
       "      <td>17.61529541015625</td>\n",
       "      <td>158.42227003991604</td>\n",
       "      <td>163.0114544820786</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>136.13362060546876</td>\n",
       "      <td>84.47034430449845</td>\n",
       "      <td>154.0</td>\n",
       "      <td>132.18185546875</td>\n",
       "      <td>76.02384449314684</td>\n",
       "      <td>137.0</td>\n",
       "      <td>127.76057373046875</td>\n",
       "      <td>64.16417538696186</td>\n",
       "      <td>134.0</td>\n",
       "      <td>9.70880126953125</td>\n",
       "      <td>110.4767248606682</td>\n",
       "      <td>159.6415851071477</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>139.55376220703124</td>\n",
       "      <td>94.06657710358374</td>\n",
       "      <td>162.0</td>\n",
       "      <td>123.07146728515625</td>\n",
       "      <td>92.99342331387841</td>\n",
       "      <td>107.0</td>\n",
       "      <td>113.6238427734375</td>\n",
       "      <td>69.71795365187482</td>\n",
       "      <td>110.0</td>\n",
       "      <td>16.95289306640625</td>\n",
       "      <td>100.29479246556758</td>\n",
       "      <td>157.6855886435509</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>116.38008056640625</td>\n",
       "      <td>84.80675153921493</td>\n",
       "      <td>115.0</td>\n",
       "      <td>94.210205078125</td>\n",
       "      <td>79.23561305577897</td>\n",
       "      <td>78.0</td>\n",
       "      <td>93.50495361328124</td>\n",
       "      <td>71.30472463139165</td>\n",
       "      <td>79.0</td>\n",
       "      <td>20.2991455078125</td>\n",
       "      <td>165.0495183339715</td>\n",
       "      <td>105.16598458170888</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>134.18507080078126</td>\n",
       "      <td>80.84780713914789</td>\n",
       "      <td>132.0</td>\n",
       "      <td>107.17276611328126</td>\n",
       "      <td>81.61152979166918</td>\n",
       "      <td>90.0</td>\n",
       "      <td>85.4860791015625</td>\n",
       "      <td>77.62625427703944</td>\n",
       "      <td>57.0</td>\n",
       "      <td>39.7902099609375</td>\n",
       "      <td>117.89052122086287</td>\n",
       "      <td>124.83618069469931</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>84.9628857421875</td>\n",
       "      <td>76.92951366495943</td>\n",
       "      <td>43.0</td>\n",
       "      <td>87.7540771484375</td>\n",
       "      <td>79.55308897403329</td>\n",
       "      <td>47.0</td>\n",
       "      <td>87.3184765625</td>\n",
       "      <td>79.04991184633612</td>\n",
       "      <td>48.0</td>\n",
       "      <td>18.4115478515625</td>\n",
       "      <td>119.01745877623557</td>\n",
       "      <td>148.8112385880947</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>136.271396484375</td>\n",
       "      <td>43.65907176147094</td>\n",
       "      <td>144.0</td>\n",
       "      <td>118.6311865234375</td>\n",
       "      <td>45.53740040883434</td>\n",
       "      <td>124.0</td>\n",
       "      <td>104.26075927734375</td>\n",
       "      <td>36.69952362612403</td>\n",
       "      <td>106.0</td>\n",
       "      <td>13.43170166015625</td>\n",
       "      <td>105.94494442462921</td>\n",
       "      <td>173.7003943097591</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>196.79904541015625</td>\n",
       "      <td>54.3689934323109</td>\n",
       "      <td>218.0</td>\n",
       "      <td>133.9017919921875</td>\n",
       "      <td>80.31247053569312</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.3592236328125</td>\n",
       "      <td>77.60363236494275</td>\n",
       "      <td>100.0</td>\n",
       "      <td>22.35732421875</td>\n",
       "      <td>173.99664340674877</td>\n",
       "      <td>138.89726930379865</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>128.16576416015624</td>\n",
       "      <td>58.986471819328436</td>\n",
       "      <td>118.0</td>\n",
       "      <td>116.99442138671876</td>\n",
       "      <td>55.388379984759474</td>\n",
       "      <td>108.0</td>\n",
       "      <td>99.43825927734375</td>\n",
       "      <td>46.14905433921131</td>\n",
       "      <td>95.0</td>\n",
       "      <td>31.4255126953125</td>\n",
       "      <td>135.72439935475592</td>\n",
       "      <td>109.68192661643032</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>140.4714599609375</td>\n",
       "      <td>50.5720515054905</td>\n",
       "      <td>148.0</td>\n",
       "      <td>128.51581787109376</td>\n",
       "      <td>57.69670522430433</td>\n",
       "      <td>137.0</td>\n",
       "      <td>120.466875</td>\n",
       "      <td>50.000567149127164</td>\n",
       "      <td>125.0</td>\n",
       "      <td>17.10853271484375</td>\n",
       "      <td>175.77999900698663</td>\n",
       "      <td>150.36444012790918</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>172.286904296875</td>\n",
       "      <td>56.65895914808838</td>\n",
       "      <td>194.0</td>\n",
       "      <td>152.9712646484375</td>\n",
       "      <td>68.05083792609489</td>\n",
       "      <td>170.0</td>\n",
       "      <td>143.45999267578125</td>\n",
       "      <td>74.46600725383409</td>\n",
       "      <td>137.0</td>\n",
       "      <td>25.66622314453125</td>\n",
       "      <td>131.88954450756313</td>\n",
       "      <td>169.19369365274906</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>158.79410888671876</td>\n",
       "      <td>69.71472981855192</td>\n",
       "      <td>176.0</td>\n",
       "      <td>150.675625</td>\n",
       "      <td>74.95277282984809</td>\n",
       "      <td>162.0</td>\n",
       "      <td>137.09406005859375</td>\n",
       "      <td>66.1061201328135</td>\n",
       "      <td>140.0</td>\n",
       "      <td>37.91630859375</td>\n",
       "      <td>108.73028443157673</td>\n",
       "      <td>62.09275864452125</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>96.63077880859375</td>\n",
       "      <td>68.82312479303901</td>\n",
       "      <td>76.0</td>\n",
       "      <td>84.80973388671875</td>\n",
       "      <td>71.44510213868351</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.38150146484375</td>\n",
       "      <td>66.96816182583737</td>\n",
       "      <td>40.0</td>\n",
       "      <td>33.47061767578125</td>\n",
       "      <td>129.88997958183288</td>\n",
       "      <td>115.32454242467877</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>135.404189453125</td>\n",
       "      <td>75.2473637219067</td>\n",
       "      <td>140.0</td>\n",
       "      <td>121.41708740234375</td>\n",
       "      <td>81.7143984292695</td>\n",
       "      <td>115.0</td>\n",
       "      <td>105.21335205078125</td>\n",
       "      <td>86.23593885010739</td>\n",
       "      <td>83.0</td>\n",
       "      <td>64.78157958984374</td>\n",
       "      <td>114.79551614642142</td>\n",
       "      <td>103.30546834588048</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>212.23322509765626</td>\n",
       "      <td>66.31094114934893</td>\n",
       "      <td>253.0</td>\n",
       "      <td>201.35588623046874</td>\n",
       "      <td>75.09158014038088</td>\n",
       "      <td>251.0</td>\n",
       "      <td>195.79020751953124</td>\n",
       "      <td>76.45935793815141</td>\n",
       "      <td>249.0</td>\n",
       "      <td>22.50113525390625</td>\n",
       "      <td>120.03946494698523</td>\n",
       "      <td>117.77616302847862</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>208.12319580078125</td>\n",
       "      <td>56.66425417503206</td>\n",
       "      <td>238.0</td>\n",
       "      <td>206.238662109375</td>\n",
       "      <td>56.584616475218326</td>\n",
       "      <td>231.0</td>\n",
       "      <td>188.0757958984375</td>\n",
       "      <td>68.7797627487246</td>\n",
       "      <td>221.0</td>\n",
       "      <td>28.37435302734375</td>\n",
       "      <td>127.52250646591187</td>\n",
       "      <td>104.21904645323752</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>162.786279296875</td>\n",
       "      <td>67.18451321285698</td>\n",
       "      <td>177.0</td>\n",
       "      <td>145.01735107421874</td>\n",
       "      <td>66.9101106663966</td>\n",
       "      <td>162.0</td>\n",
       "      <td>125.1653369140625</td>\n",
       "      <td>63.670486699847615</td>\n",
       "      <td>131.0</td>\n",
       "      <td>28.86243896484375</td>\n",
       "      <td>184.0710210835934</td>\n",
       "      <td>147.4687121683359</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>139.64635498046874</td>\n",
       "      <td>56.72837970203387</td>\n",
       "      <td>149.0</td>\n",
       "      <td>130.000078125</td>\n",
       "      <td>57.87819164722816</td>\n",
       "      <td>134.0</td>\n",
       "      <td>104.7968896484375</td>\n",
       "      <td>55.900358663645</td>\n",
       "      <td>96.0</td>\n",
       "      <td>17.08985595703125</td>\n",
       "      <td>123.77658612012863</td>\n",
       "      <td>92.21489186346531</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>165.47344482421875</td>\n",
       "      <td>59.99706001015135</td>\n",
       "      <td>184.0</td>\n",
       "      <td>146.11522216796874</td>\n",
       "      <td>62.1271842605552</td>\n",
       "      <td>151.0</td>\n",
       "      <td>110.8405078125</td>\n",
       "      <td>60.774541256816576</td>\n",
       "      <td>99.0</td>\n",
       "      <td>47.10029296875</td>\n",
       "      <td>140.56607634186747</td>\n",
       "      <td>183.29186334729192</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>204.527138671875</td>\n",
       "      <td>71.18721727347491</td>\n",
       "      <td>252.0</td>\n",
       "      <td>200.01259521484374</td>\n",
       "      <td>72.16692885365954</td>\n",
       "      <td>239.0</td>\n",
       "      <td>196.25411376953124</td>\n",
       "      <td>70.93358558115587</td>\n",
       "      <td>227.0</td>\n",
       "      <td>16.51834716796875</td>\n",
       "      <td>118.14035281419756</td>\n",
       "      <td>128.49148563086987</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>126.1930126953125</td>\n",
       "      <td>69.73526608498167</td>\n",
       "      <td>112.0</td>\n",
       "      <td>116.13961181640624</td>\n",
       "      <td>67.81395838902472</td>\n",
       "      <td>104.0</td>\n",
       "      <td>101.3563671875</td>\n",
       "      <td>59.896751207073386</td>\n",
       "      <td>84.0</td>\n",
       "      <td>18.35614013671875</td>\n",
       "      <td>166.37522833049297</td>\n",
       "      <td>162.91405628442766</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>123.59750732421875</td>\n",
       "      <td>71.19714424586871</td>\n",
       "      <td>116.0</td>\n",
       "      <td>106.650830078125</td>\n",
       "      <td>68.50605854889567</td>\n",
       "      <td>89.0</td>\n",
       "      <td>97.683955078125</td>\n",
       "      <td>68.47226983751237</td>\n",
       "      <td>74.0</td>\n",
       "      <td>46.535009765625</td>\n",
       "      <td>139.9635199660063</td>\n",
       "      <td>150.12871173620223</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>111.24941162109376</td>\n",
       "      <td>55.121743618347715</td>\n",
       "      <td>121.0</td>\n",
       "      <td>104.69441650390625</td>\n",
       "      <td>51.15345069154863</td>\n",
       "      <td>116.0</td>\n",
       "      <td>93.84418701171874</td>\n",
       "      <td>46.32493641164715</td>\n",
       "      <td>104.0</td>\n",
       "      <td>29.60390625</td>\n",
       "      <td>159.72640417098998</td>\n",
       "      <td>111.40358545929192</td>\n",
       "      <td>3.521959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>125.1178969478738</td>\n",
       "      <td>74.19655613563118</td>\n",
       "      <td>110.0</td>\n",
       "      <td>130.95579218106997</td>\n",
       "      <td>69.30350969584853</td>\n",
       "      <td>127.0</td>\n",
       "      <td>99.68410665294924</td>\n",
       "      <td>74.4874325426642</td>\n",
       "      <td>80.0</td>\n",
       "      <td>44.388670267489715</td>\n",
       "      <td>144.75191037284006</td>\n",
       "      <td>140.08726437250772</td>\n",
       "      <td>-0.660599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>248.086996</td>\n",
       "      <td>28.49433072904124</td>\n",
       "      <td>255.0</td>\n",
       "      <td>231.105144</td>\n",
       "      <td>55.45992362723973</td>\n",
       "      <td>255.0</td>\n",
       "      <td>215.938192</td>\n",
       "      <td>77.20732496189164</td>\n",
       "      <td>255.0</td>\n",
       "      <td>14.50338</td>\n",
       "      <td>120.89605960235596</td>\n",
       "      <td>129.79170090637206</td>\n",
       "      <td>-0.660599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>87.35707368421053</td>\n",
       "      <td>50.09871614448691</td>\n",
       "      <td>74.0</td>\n",
       "      <td>91.19876232686981</td>\n",
       "      <td>52.8187674026601</td>\n",
       "      <td>78.0</td>\n",
       "      <td>101.3015135734072</td>\n",
       "      <td>56.422919169169106</td>\n",
       "      <td>90.0</td>\n",
       "      <td>4.1373573407202215</td>\n",
       "      <td>222.88913876182156</td>\n",
       "      <td>190.42831718685753</td>\n",
       "      <td>-0.660599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>99.54789008916323</td>\n",
       "      <td>58.11114845875146</td>\n",
       "      <td>81.0</td>\n",
       "      <td>86.87988340192044</td>\n",
       "      <td>49.53221602695147</td>\n",
       "      <td>72.0</td>\n",
       "      <td>91.7157390260631</td>\n",
       "      <td>46.83367884140012</td>\n",
       "      <td>80.0</td>\n",
       "      <td>22.08185442386831</td>\n",
       "      <td>175.5379239273071</td>\n",
       "      <td>71.20387400256263</td>\n",
       "      <td>-0.660599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>79.26930469821673</td>\n",
       "      <td>67.92348093649912</td>\n",
       "      <td>62.0</td>\n",
       "      <td>77.13179098079561</td>\n",
       "      <td>51.24230271045756</td>\n",
       "      <td>69.0</td>\n",
       "      <td>87.1278883744856</td>\n",
       "      <td>50.816484659852954</td>\n",
       "      <td>81.0</td>\n",
       "      <td>38.95264917695473</td>\n",
       "      <td>155.83816740353905</td>\n",
       "      <td>85.87959598700206</td>\n",
       "      <td>-0.660599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>117.04447395479116</td>\n",
       "      <td>81.53665156841596</td>\n",
       "      <td>106.0</td>\n",
       "      <td>110.51809030810736</td>\n",
       "      <td>77.9766783267298</td>\n",
       "      <td>86.0</td>\n",
       "      <td>109.49181141599168</td>\n",
       "      <td>77.14310108584465</td>\n",
       "      <td>81.0</td>\n",
       "      <td>37.68176529174953</td>\n",
       "      <td>135.88731328529343</td>\n",
       "      <td>123.24657375054898</td>\n",
       "      <td>-2.054351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>94.39349544595291</td>\n",
       "      <td>71.5480080986561</td>\n",
       "      <td>72.0</td>\n",
       "      <td>74.78281960349325</td>\n",
       "      <td>54.94596711386663</td>\n",
       "      <td>58.0</td>\n",
       "      <td>75.27862878657689</td>\n",
       "      <td>47.6843515177594</td>\n",
       "      <td>60.0</td>\n",
       "      <td>29.540982518083396</td>\n",
       "      <td>149.02517080872425</td>\n",
       "      <td>123.65360443130314</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>186.87726680384088</td>\n",
       "      <td>54.4993618688067</td>\n",
       "      <td>205.0</td>\n",
       "      <td>139.2564651920439</td>\n",
       "      <td>78.56563925965854</td>\n",
       "      <td>151.0</td>\n",
       "      <td>146.3700342935528</td>\n",
       "      <td>27.547483482643806</td>\n",
       "      <td>141.0</td>\n",
       "      <td>8.155234053497942</td>\n",
       "      <td>156.53544275601706</td>\n",
       "      <td>95.38747037039863</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>121.33652800039864</td>\n",
       "      <td>83.52007010721105</td>\n",
       "      <td>81.0</td>\n",
       "      <td>135.07413067129534</td>\n",
       "      <td>80.69058944915943</td>\n",
       "      <td>134.0</td>\n",
       "      <td>123.80713235721582</td>\n",
       "      <td>81.65503659344856</td>\n",
       "      <td>122.0</td>\n",
       "      <td>37.89135363635609</td>\n",
       "      <td>123.98464527679796</td>\n",
       "      <td>133.47341881457945</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>69.49704953693558</td>\n",
       "      <td>75.34628101389848</td>\n",
       "      <td>42.0</td>\n",
       "      <td>63.33278950657868</td>\n",
       "      <td>74.59613627700057</td>\n",
       "      <td>30.0</td>\n",
       "      <td>28.566139885228203</td>\n",
       "      <td>54.496954176709714</td>\n",
       "      <td>6.0</td>\n",
       "      <td>41.40197725667811</td>\n",
       "      <td>122.3907261383839</td>\n",
       "      <td>71.05887754880462</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>201.26694005894274</td>\n",
       "      <td>47.244717871754624</td>\n",
       "      <td>215.0</td>\n",
       "      <td>197.21367638883078</td>\n",
       "      <td>52.18372390154471</td>\n",
       "      <td>213.0</td>\n",
       "      <td>196.85144756427806</td>\n",
       "      <td>51.94419048933288</td>\n",
       "      <td>213.0</td>\n",
       "      <td>31.96474793909649</td>\n",
       "      <td>170.81963162223985</td>\n",
       "      <td>82.64895269911563</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>197.10124399862826</td>\n",
       "      <td>50.30450460241824</td>\n",
       "      <td>218.0</td>\n",
       "      <td>171.82180041152264</td>\n",
       "      <td>50.546507151011895</td>\n",
       "      <td>191.0</td>\n",
       "      <td>141.13645318930043</td>\n",
       "      <td>60.471586995186684</td>\n",
       "      <td>155.0</td>\n",
       "      <td>4.376581790123457</td>\n",
       "      <td>127.65929981019761</td>\n",
       "      <td>97.03329790115357</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>117.63114013671876</td>\n",
       "      <td>72.14466366022752</td>\n",
       "      <td>123.0</td>\n",
       "      <td>121.45970947265624</td>\n",
       "      <td>77.1852414757731</td>\n",
       "      <td>125.0</td>\n",
       "      <td>133.3261767578125</td>\n",
       "      <td>78.30484191239894</td>\n",
       "      <td>134.0</td>\n",
       "      <td>19.79549560546875</td>\n",
       "      <td>149.3036707019806</td>\n",
       "      <td>201.25688803911208</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>102.57670655567118</td>\n",
       "      <td>79.42805382363625</td>\n",
       "      <td>70.0</td>\n",
       "      <td>88.9288813735692</td>\n",
       "      <td>71.80374389438364</td>\n",
       "      <td>61.0</td>\n",
       "      <td>91.04268990634756</td>\n",
       "      <td>68.97649947903614</td>\n",
       "      <td>66.0</td>\n",
       "      <td>41.318093132154004</td>\n",
       "      <td>126.7999579958762</td>\n",
       "      <td>150.46037159396755</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>122.90103395061729</td>\n",
       "      <td>96.51625166087224</td>\n",
       "      <td>130.0</td>\n",
       "      <td>117.41522290809328</td>\n",
       "      <td>62.91201497331364</td>\n",
       "      <td>109.0</td>\n",
       "      <td>119.87191015089164</td>\n",
       "      <td>36.767785218726715</td>\n",
       "      <td>112.0</td>\n",
       "      <td>14.263297325102881</td>\n",
       "      <td>129.75562614123027</td>\n",
       "      <td>158.58726731618245</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>71.0858669764989</td>\n",
       "      <td>74.32045606276391</td>\n",
       "      <td>30.0</td>\n",
       "      <td>58.25439399428497</td>\n",
       "      <td>57.75535930557458</td>\n",
       "      <td>25.0</td>\n",
       "      <td>60.321535984771344</td>\n",
       "      <td>44.230209913361854</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.01098632550821</td>\n",
       "      <td>84.8287985705352</td>\n",
       "      <td>105.38948981367479</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>178.19056712962964</td>\n",
       "      <td>79.74266502598158</td>\n",
       "      <td>216.0</td>\n",
       "      <td>100.16647782651071</td>\n",
       "      <td>79.4148352032687</td>\n",
       "      <td>91.0</td>\n",
       "      <td>46.86748751218324</td>\n",
       "      <td>36.072666009334306</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.967288011695906</td>\n",
       "      <td>200.30170420910179</td>\n",
       "      <td>71.18859691725837</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>130.75233195771384</td>\n",
       "      <td>97.55606089338357</td>\n",
       "      <td>169.0</td>\n",
       "      <td>129.3490785233761</td>\n",
       "      <td>98.44239409234055</td>\n",
       "      <td>167.0</td>\n",
       "      <td>125.80775905930238</td>\n",
       "      <td>97.96198853165207</td>\n",
       "      <td>156.0</td>\n",
       "      <td>31.88833455820001</td>\n",
       "      <td>101.71300473033934</td>\n",
       "      <td>164.98771401025297</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>100.4856319188192</td>\n",
       "      <td>79.01793128869522</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.4856319188192</td>\n",
       "      <td>79.01793128869522</td>\n",
       "      <td>62.0</td>\n",
       "      <td>100.4856319188192</td>\n",
       "      <td>79.01793128869522</td>\n",
       "      <td>62.0</td>\n",
       "      <td>16.344268911439116</td>\n",
       "      <td>110.45762436574674</td>\n",
       "      <td>151.56515159606937</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>159.2265889685089</td>\n",
       "      <td>69.27391330943901</td>\n",
       "      <td>169.0</td>\n",
       "      <td>141.45923660873623</td>\n",
       "      <td>62.295665601311946</td>\n",
       "      <td>146.0</td>\n",
       "      <td>125.69456318809543</td>\n",
       "      <td>52.53690594599959</td>\n",
       "      <td>123.0</td>\n",
       "      <td>5.527520385470719</td>\n",
       "      <td>37.66888929597531</td>\n",
       "      <td>264.0275328424242</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>78.05525173611112</td>\n",
       "      <td>59.007357439287844</td>\n",
       "      <td>47.0</td>\n",
       "      <td>72.2366015625</td>\n",
       "      <td>56.27991130414131</td>\n",
       "      <td>43.0</td>\n",
       "      <td>78.48717447916667</td>\n",
       "      <td>48.33138232864525</td>\n",
       "      <td>55.0</td>\n",
       "      <td>22.354557291666666</td>\n",
       "      <td>163.8624595737457</td>\n",
       "      <td>112.50854230880736</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>221.55266392318245</td>\n",
       "      <td>56.635700424626286</td>\n",
       "      <td>248.0</td>\n",
       "      <td>201.53990877914953</td>\n",
       "      <td>62.274155784080556</td>\n",
       "      <td>230.0</td>\n",
       "      <td>188.06073868312757</td>\n",
       "      <td>59.57318253149098</td>\n",
       "      <td>203.0</td>\n",
       "      <td>1.9207201646090535</td>\n",
       "      <td>94.90010888502334</td>\n",
       "      <td>103.37445483419631</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>177.4711172839506</td>\n",
       "      <td>77.5715657345364</td>\n",
       "      <td>209.0</td>\n",
       "      <td>120.86715706447188</td>\n",
       "      <td>66.36058766215804</td>\n",
       "      <td>120.0</td>\n",
       "      <td>115.68830589849108</td>\n",
       "      <td>42.92622828174257</td>\n",
       "      <td>103.0</td>\n",
       "      <td>8.04037037037037</td>\n",
       "      <td>92.6163373345269</td>\n",
       "      <td>119.42616708119711</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>73.37782877604167</td>\n",
       "      <td>64.15942806485032</td>\n",
       "      <td>47.0</td>\n",
       "      <td>68.11454752604166</td>\n",
       "      <td>60.46437430838843</td>\n",
       "      <td>42.0</td>\n",
       "      <td>64.07443359375</td>\n",
       "      <td>49.3248875442682</td>\n",
       "      <td>46.0</td>\n",
       "      <td>39.643701171875</td>\n",
       "      <td>197.09572540760044</td>\n",
       "      <td>112.55124348521231</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>162.75912743972447</td>\n",
       "      <td>69.84286052704863</td>\n",
       "      <td>163.0</td>\n",
       "      <td>158.69814323607426</td>\n",
       "      <td>69.68202296798391</td>\n",
       "      <td>182.0</td>\n",
       "      <td>148.80072053525475</td>\n",
       "      <td>91.85406069933852</td>\n",
       "      <td>170.0</td>\n",
       "      <td>37.88000316718793</td>\n",
       "      <td>236.77001704815527</td>\n",
       "      <td>78.1363587348141</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>133.14432373113854</td>\n",
       "      <td>54.57942708243568</td>\n",
       "      <td>134.0</td>\n",
       "      <td>119.99443278463649</td>\n",
       "      <td>62.44554449522522</td>\n",
       "      <td>118.0</td>\n",
       "      <td>104.6197695473251</td>\n",
       "      <td>68.16983012250951</td>\n",
       "      <td>94.0</td>\n",
       "      <td>11.266522633744856</td>\n",
       "      <td>132.36230394405789</td>\n",
       "      <td>255.31213697221543</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>200.85675034293553</td>\n",
       "      <td>62.04075852388396</td>\n",
       "      <td>225.0</td>\n",
       "      <td>145.50102880658437</td>\n",
       "      <td>65.85936922501301</td>\n",
       "      <td>151.0</td>\n",
       "      <td>132.9871426611797</td>\n",
       "      <td>29.473453715515983</td>\n",
       "      <td>132.0</td>\n",
       "      <td>7.565874485596708</td>\n",
       "      <td>76.40932021925185</td>\n",
       "      <td>145.16060996585423</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>136.980265625</td>\n",
       "      <td>94.29730328821415</td>\n",
       "      <td>152.0</td>\n",
       "      <td>105.8918125</td>\n",
       "      <td>80.40773049645067</td>\n",
       "      <td>104.0</td>\n",
       "      <td>78.8865703125</td>\n",
       "      <td>64.36889777597169</td>\n",
       "      <td>68.0</td>\n",
       "      <td>39.5070703125</td>\n",
       "      <td>98.22000203704833</td>\n",
       "      <td>166.20779390215873</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>194.95287037037036</td>\n",
       "      <td>86.6421837707523</td>\n",
       "      <td>247.0</td>\n",
       "      <td>190.31729423868313</td>\n",
       "      <td>87.66619419643676</td>\n",
       "      <td>249.0</td>\n",
       "      <td>180.2115706447188</td>\n",
       "      <td>89.68120859333997</td>\n",
       "      <td>241.0</td>\n",
       "      <td>26.87469135802469</td>\n",
       "      <td>125.0970919693841</td>\n",
       "      <td>133.93289755291408</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>169.92966392318243</td>\n",
       "      <td>59.502307923074504</td>\n",
       "      <td>204.0</td>\n",
       "      <td>170.84127229080931</td>\n",
       "      <td>57.99138861288768</td>\n",
       "      <td>204.0</td>\n",
       "      <td>184.82224965706448</td>\n",
       "      <td>43.719024968365716</td>\n",
       "      <td>209.0</td>\n",
       "      <td>21.632150205761317</td>\n",
       "      <td>147.782752978007</td>\n",
       "      <td>120.38230752097236</td>\n",
       "      <td>-0.215174</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 R_Mean               R_STD  R_MED              G_Mean  \\\n",
       "0     138.5661978298945   68.85854358506768  168.0  133.85562977914478   \n",
       "1    134.14220225127087   39.89299878365912  136.0     136.18835437225   \n",
       "2     151.1995119398522  51.268360928596465  165.0  153.80132374300482   \n",
       "3      143.861954803708   43.83359910090871  157.0   144.2480135845188   \n",
       "4     152.3564599609375   71.13307536516064  172.0  136.37180419921876   \n",
       "5    169.93778076171876   55.94774983219537  195.0  162.66536865234374   \n",
       "6         114.598359375   62.32804919182335   97.0      96.28396484375   \n",
       "7     164.6656982421875   68.48715507526556  190.0    138.269208984375   \n",
       "8    136.13362060546876   84.47034430449845  154.0     132.18185546875   \n",
       "9    139.55376220703124   94.06657710358374  162.0  123.07146728515625   \n",
       "10   116.38008056640625   84.80675153921493  115.0     94.210205078125   \n",
       "11   134.18507080078126   80.84780713914789  132.0  107.17276611328126   \n",
       "12     84.9628857421875   76.92951366495943   43.0    87.7540771484375   \n",
       "13     136.271396484375   43.65907176147094  144.0   118.6311865234375   \n",
       "14   196.79904541015625    54.3689934323109  218.0   133.9017919921875   \n",
       "15   128.16576416015624  58.986471819328436  118.0  116.99442138671876   \n",
       "16    140.4714599609375    50.5720515054905  148.0  128.51581787109376   \n",
       "17     172.286904296875   56.65895914808838  194.0   152.9712646484375   \n",
       "18   158.79410888671876   69.71472981855192  176.0          150.675625   \n",
       "19    96.63077880859375   68.82312479303901   76.0   84.80973388671875   \n",
       "20     135.404189453125    75.2473637219067  140.0  121.41708740234375   \n",
       "21   212.23322509765626   66.31094114934893  253.0  201.35588623046874   \n",
       "22   208.12319580078125   56.66425417503206  238.0    206.238662109375   \n",
       "23     162.786279296875   67.18451321285698  177.0  145.01735107421874   \n",
       "24   139.64635498046874   56.72837970203387  149.0       130.000078125   \n",
       "25   165.47344482421875   59.99706001015135  184.0  146.11522216796874   \n",
       "26     204.527138671875   71.18721727347491  252.0  200.01259521484374   \n",
       "27    126.1930126953125   69.73526608498167  112.0  116.13961181640624   \n",
       "28   123.59750732421875   71.19714424586871  116.0    106.650830078125   \n",
       "29   111.24941162109376  55.121743618347715  121.0  104.69441650390625   \n",
       "..                  ...                 ...    ...                 ...   \n",
       "267   125.1178969478738   74.19655613563118  110.0  130.95579218106997   \n",
       "268          248.086996   28.49433072904124  255.0          231.105144   \n",
       "269   87.35707368421053   50.09871614448691   74.0   91.19876232686981   \n",
       "270   99.54789008916323   58.11114845875146   81.0   86.87988340192044   \n",
       "271   79.26930469821673   67.92348093649912   62.0   77.13179098079561   \n",
       "272  117.04447395479116   81.53665156841596  106.0  110.51809030810736   \n",
       "273   94.39349544595291    71.5480080986561   72.0   74.78281960349325   \n",
       "274  186.87726680384088    54.4993618688067  205.0   139.2564651920439   \n",
       "275  121.33652800039864   83.52007010721105   81.0  135.07413067129534   \n",
       "276   69.49704953693558   75.34628101389848   42.0   63.33278950657868   \n",
       "277  201.26694005894274  47.244717871754624  215.0  197.21367638883078   \n",
       "278  197.10124399862826   50.30450460241824  218.0  171.82180041152264   \n",
       "279  117.63114013671876   72.14466366022752  123.0  121.45970947265624   \n",
       "280  102.57670655567118   79.42805382363625   70.0    88.9288813735692   \n",
       "281  122.90103395061729   96.51625166087224  130.0  117.41522290809328   \n",
       "282    71.0858669764989   74.32045606276391   30.0   58.25439399428497   \n",
       "283  178.19056712962964   79.74266502598158  216.0  100.16647782651071   \n",
       "284  130.75233195771384   97.55606089338357  169.0   129.3490785233761   \n",
       "285   100.4856319188192   79.01793128869522   62.0   100.4856319188192   \n",
       "286   159.2265889685089   69.27391330943901  169.0  141.45923660873623   \n",
       "287   78.05525173611112  59.007357439287844   47.0       72.2366015625   \n",
       "288  221.55266392318245  56.635700424626286  248.0  201.53990877914953   \n",
       "289   177.4711172839506    77.5715657345364  209.0  120.86715706447188   \n",
       "290   73.37782877604167   64.15942806485032   47.0   68.11454752604166   \n",
       "291  162.75912743972447   69.84286052704863  163.0  158.69814323607426   \n",
       "292  133.14432373113854   54.57942708243568  134.0  119.99443278463649   \n",
       "293  200.85675034293553   62.04075852388396  225.0  145.50102880658437   \n",
       "294       136.980265625   94.29730328821415  152.0         105.8918125   \n",
       "295  194.95287037037036    86.6421837707523  247.0  190.31729423868313   \n",
       "296  169.92966392318243  59.502307923074504  204.0  170.84127229080931   \n",
       "\n",
       "                  G_STD  G_MED              B_Mean               B_STD  B_MED  \\\n",
       "0     84.97953749629683  167.0  135.93238711606648   68.48064869294063  155.0   \n",
       "1     42.46455028864543  145.0  139.70720662992866  47.352066977158835  152.0   \n",
       "2     54.62034510182328  165.0   155.4477337776069   57.38931896695739  168.0   \n",
       "3    43.783710809740576  158.0  142.78141953949336  41.879963576873514  155.0   \n",
       "4     81.45707132690796  150.0    129.059794921875  58.861371280828195  135.0   \n",
       "5     60.42389665519665  187.0    147.715810546875  50.294297687803734  172.0   \n",
       "6     64.98113367053654   71.0   83.50236083984375   64.24198400637135   62.0   \n",
       "7     78.75741397490727  150.0  128.38324462890625   63.41391742252502  124.0   \n",
       "8     76.02384449314684  137.0  127.76057373046875   64.16417538696186  134.0   \n",
       "9     92.99342331387841  107.0   113.6238427734375   69.71795365187482  110.0   \n",
       "10    79.23561305577897   78.0   93.50495361328124   71.30472463139165   79.0   \n",
       "11    81.61152979166918   90.0    85.4860791015625   77.62625427703944   57.0   \n",
       "12    79.55308897403329   47.0       87.3184765625   79.04991184633612   48.0   \n",
       "13    45.53740040883434  124.0  104.26075927734375   36.69952362612403  106.0   \n",
       "14    80.31247053569312  156.0   105.3592236328125   77.60363236494275  100.0   \n",
       "15   55.388379984759474  108.0   99.43825927734375   46.14905433921131   95.0   \n",
       "16    57.69670522430433  137.0          120.466875  50.000567149127164  125.0   \n",
       "17    68.05083792609489  170.0  143.45999267578125   74.46600725383409  137.0   \n",
       "18    74.95277282984809  162.0  137.09406005859375    66.1061201328135  140.0   \n",
       "19    71.44510213868351   50.0   74.38150146484375   66.96816182583737   40.0   \n",
       "20     81.7143984292695  115.0  105.21335205078125   86.23593885010739   83.0   \n",
       "21    75.09158014038088  251.0  195.79020751953124   76.45935793815141  249.0   \n",
       "22   56.584616475218326  231.0   188.0757958984375    68.7797627487246  221.0   \n",
       "23     66.9101106663966  162.0   125.1653369140625  63.670486699847615  131.0   \n",
       "24    57.87819164722816  134.0   104.7968896484375     55.900358663645   96.0   \n",
       "25     62.1271842605552  151.0      110.8405078125  60.774541256816576   99.0   \n",
       "26    72.16692885365954  239.0  196.25411376953124   70.93358558115587  227.0   \n",
       "27    67.81395838902472  104.0      101.3563671875  59.896751207073386   84.0   \n",
       "28    68.50605854889567   89.0     97.683955078125   68.47226983751237   74.0   \n",
       "29    51.15345069154863  116.0   93.84418701171874   46.32493641164715  104.0   \n",
       "..                  ...    ...                 ...                 ...    ...   \n",
       "267   69.30350969584853  127.0   99.68410665294924    74.4874325426642   80.0   \n",
       "268   55.45992362723973  255.0          215.938192   77.20732496189164  255.0   \n",
       "269    52.8187674026601   78.0   101.3015135734072  56.422919169169106   90.0   \n",
       "270   49.53221602695147   72.0    91.7157390260631   46.83367884140012   80.0   \n",
       "271   51.24230271045756   69.0    87.1278883744856  50.816484659852954   81.0   \n",
       "272    77.9766783267298   86.0  109.49181141599168   77.14310108584465   81.0   \n",
       "273   54.94596711386663   58.0   75.27862878657689    47.6843515177594   60.0   \n",
       "274   78.56563925965854  151.0   146.3700342935528  27.547483482643806  141.0   \n",
       "275   80.69058944915943  134.0  123.80713235721582   81.65503659344856  122.0   \n",
       "276   74.59613627700057   30.0  28.566139885228203  54.496954176709714    6.0   \n",
       "277   52.18372390154471  213.0  196.85144756427806   51.94419048933288  213.0   \n",
       "278  50.546507151011895  191.0  141.13645318930043  60.471586995186684  155.0   \n",
       "279    77.1852414757731  125.0   133.3261767578125   78.30484191239894  134.0   \n",
       "280   71.80374389438364   61.0   91.04268990634756   68.97649947903614   66.0   \n",
       "281   62.91201497331364  109.0  119.87191015089164  36.767785218726715  112.0   \n",
       "282   57.75535930557458   25.0  60.321535984771344  44.230209913361854   34.0   \n",
       "283    79.4148352032687   91.0   46.86748751218324  36.072666009334306   33.0   \n",
       "284   98.44239409234055  167.0  125.80775905930238   97.96198853165207  156.0   \n",
       "285   79.01793128869522   62.0   100.4856319188192   79.01793128869522   62.0   \n",
       "286  62.295665601311946  146.0  125.69456318809543   52.53690594599959  123.0   \n",
       "287   56.27991130414131   43.0   78.48717447916667   48.33138232864525   55.0   \n",
       "288  62.274155784080556  230.0  188.06073868312757   59.57318253149098  203.0   \n",
       "289   66.36058766215804  120.0  115.68830589849108   42.92622828174257  103.0   \n",
       "290   60.46437430838843   42.0      64.07443359375    49.3248875442682   46.0   \n",
       "291   69.68202296798391  182.0  148.80072053525475   91.85406069933852  170.0   \n",
       "292   62.44554449522522  118.0   104.6197695473251   68.16983012250951   94.0   \n",
       "293   65.85936922501301  151.0   132.9871426611797  29.473453715515983  132.0   \n",
       "294   80.40773049645067  104.0       78.8865703125   64.36889777597169   68.0   \n",
       "295   87.66619419643676  249.0   180.2115706447188   89.68120859333997  241.0   \n",
       "296   57.99138861288768  204.0  184.82224965706448  43.719024968365716  209.0   \n",
       "\n",
       "                  Canny               ORB_X               ORB_Y  final_score  \n",
       "0    14.965277777777779  127.16971705754598  125.47407576243084     3.521959  \n",
       "1      8.80923202614379  183.53733704884849  61.022005335489915     3.521959  \n",
       "2    10.103485838779957  152.41735134124758  110.90057148933411     3.521959  \n",
       "3    12.883986928104575   91.61554183959959    72.7517301559448     3.521959  \n",
       "4     18.70103759765625  119.66093983769417  120.46904077291488     3.521959  \n",
       "5       13.404931640625  121.81377463102342  103.98939337313175     3.521959  \n",
       "6      14.2304443359375  116.57670060396194  119.93656636208296     3.521959  \n",
       "7     17.61529541015625  158.42227003991604   163.0114544820786     3.521959  \n",
       "8      9.70880126953125   110.4767248606682   159.6415851071477     3.521959  \n",
       "9     16.95289306640625  100.29479246556758   157.6855886435509     3.521959  \n",
       "10     20.2991455078125   165.0495183339715  105.16598458170888     3.521959  \n",
       "11     39.7902099609375  117.89052122086287  124.83618069469931     3.521959  \n",
       "12     18.4115478515625  119.01745877623557   148.8112385880947     3.521959  \n",
       "13    13.43170166015625  105.94494442462921   173.7003943097591     3.521959  \n",
       "14       22.35732421875  173.99664340674877  138.89726930379865     3.521959  \n",
       "15     31.4255126953125  135.72439935475592  109.68192661643032     3.521959  \n",
       "16    17.10853271484375  175.77999900698663  150.36444012790918     3.521959  \n",
       "17    25.66622314453125  131.88954450756313  169.19369365274906     3.521959  \n",
       "18       37.91630859375  108.73028443157673   62.09275864452125     3.521959  \n",
       "19    33.47061767578125  129.88997958183288  115.32454242467877     3.521959  \n",
       "20    64.78157958984374  114.79551614642142  103.30546834588048     3.521959  \n",
       "21    22.50113525390625  120.03946494698523  117.77616302847862     3.521959  \n",
       "22    28.37435302734375  127.52250646591187  104.21904645323752     3.521959  \n",
       "23    28.86243896484375   184.0710210835934   147.4687121683359     3.521959  \n",
       "24    17.08985595703125  123.77658612012863   92.21489186346531     3.521959  \n",
       "25       47.10029296875  140.56607634186747  183.29186334729192     3.521959  \n",
       "26    16.51834716796875  118.14035281419756  128.49148563086987     3.521959  \n",
       "27    18.35614013671875  166.37522833049297  162.91405628442766     3.521959  \n",
       "28      46.535009765625   139.9635199660063  150.12871173620223     3.521959  \n",
       "29          29.60390625  159.72640417098998  111.40358545929192     3.521959  \n",
       "..                  ...                 ...                 ...          ...  \n",
       "267  44.388670267489715  144.75191037284006  140.08726437250772    -0.660599  \n",
       "268            14.50338  120.89605960235596  129.79170090637206    -0.660599  \n",
       "269  4.1373573407202215  222.88913876182156  190.42831718685753    -0.660599  \n",
       "270   22.08185442386831   175.5379239273071   71.20387400256263    -0.660599  \n",
       "271   38.95264917695473  155.83816740353905   85.87959598700206    -0.660599  \n",
       "272   37.68176529174953  135.88731328529343  123.24657375054898    -2.054351  \n",
       "273  29.540982518083396  149.02517080872425  123.65360443130314    -0.215174  \n",
       "274   8.155234053497942  156.53544275601706   95.38747037039863    -0.215174  \n",
       "275   37.89135363635609  123.98464527679796  133.47341881457945    -0.215174  \n",
       "276   41.40197725667811   122.3907261383839   71.05887754880462    -0.215174  \n",
       "277   31.96474793909649  170.81963162223985   82.64895269911563    -0.215174  \n",
       "278   4.376581790123457  127.65929981019761   97.03329790115357    -0.215174  \n",
       "279   19.79549560546875   149.3036707019806  201.25688803911208    -0.215174  \n",
       "280  41.318093132154004   126.7999579958762  150.46037159396755    -0.215174  \n",
       "281  14.263297325102881  129.75562614123027  158.58726731618245    -0.215174  \n",
       "282   35.01098632550821    84.8287985705352  105.38948981367479    -0.215174  \n",
       "283  20.967288011695906  200.30170420910179   71.18859691725837    -0.215174  \n",
       "284   31.88833455820001  101.71300473033934  164.98771401025297    -0.215174  \n",
       "285  16.344268911439116  110.45762436574674  151.56515159606937    -0.215174  \n",
       "286   5.527520385470719   37.66888929597531   264.0275328424242    -0.215174  \n",
       "287  22.354557291666666   163.8624595737457  112.50854230880736    -0.215174  \n",
       "288  1.9207201646090535   94.90010888502334  103.37445483419631    -0.215174  \n",
       "289    8.04037037037037    92.6163373345269  119.42616708119711    -0.215174  \n",
       "290     39.643701171875  197.09572540760044  112.55124348521231    -0.215174  \n",
       "291   37.88000316718793  236.77001704815527    78.1363587348141    -0.215174  \n",
       "292  11.266522633744856  132.36230394405789  255.31213697221543    -0.215174  \n",
       "293   7.565874485596708   76.40932021925185  145.16060996585423    -0.215174  \n",
       "294       39.5070703125   98.22000203704833  166.20779390215873    -0.215174  \n",
       "295   26.87469135802469   125.0970919693841  133.93289755291408    -0.215174  \n",
       "296  21.632150205761317    147.782752978007  120.38230752097236    -0.215174  \n",
       "\n",
       "[297 rows x 13 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = train_df.merge(df_usernames,how='left',on='User_Handle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop extra columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['User_Handle', 'URL', 'R_Mean', 'R_STD', 'R_MED', 'G_Mean', 'G_STD',\n",
       "       'G_MED', 'B_Mean', 'B_STD', 'B_MED', 'Canny', 'ORB_X', 'ORB_Y',\n",
       "       'Unnamed: 0', 'followers', 'username', 'id_post', 'video_count',\n",
       "       'url_img', 'link_post', 'owner', 'caption', 'comment_count',\n",
       "       'taken_at_timestamp', 'taken_at_time', 'shortcode', 'is_video',\n",
       "       'likes_count', 'likes_score', 'comments_score', 'zscore_likes',\n",
       "       'zscore_comments', 'final_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remove = ['User_Handle', 'URL', 'Unnamed: 0', 'username',  'followers', 'username', 'id_post', 'video_count',\n",
    "       'url_img', 'link_post', 'owner', 'caption', 'comment_count',\n",
    "       'taken_at_timestamp', 'taken_at_time', 'shortcode', 'is_video',\n",
    "       'likes_count', 'likes_score', 'comments_score',\n",
    "       'zscore_likes', 'zscore_comments',]\n",
    "df.drop(remove, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R_Mean         0\n",
      "R_STD          0\n",
      "R_MED          0\n",
      "G_Mean         0\n",
      "G_STD          0\n",
      "G_MED          0\n",
      "B_Mean         0\n",
      "B_STD          0\n",
      "B_MED          0\n",
      "Canny          0\n",
      "ORB_X          0\n",
      "ORB_Y          0\n",
      "final_score    4\n",
      "dtype: int64\n",
      "R_Mean         0\n",
      "R_STD          0\n",
      "R_MED          0\n",
      "G_Mean         0\n",
      "G_STD          0\n",
      "G_MED          0\n",
      "B_Mean         0\n",
      "B_STD          0\n",
      "B_MED          0\n",
      "Canny          0\n",
      "ORB_X          0\n",
      "ORB_Y          0\n",
      "final_score    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## any null?\n",
    "print(df.isnull().sum(axis=0))\n",
    "df = df.dropna()\n",
    "print(df.isnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rands = np.random.seed(9001)\n",
    "msk = np.random.rand(len(df)) < 0.05\n",
    "data_train = df[~msk]\n",
    "data_test = df[msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = data_train.final_score\n",
    "y_test = data_test.final_score\n",
    "\n",
    "predictors = ['R_Mean', 'R_STD', 'R_MED', 'G_Mean', 'G_STD', 'G_MED', 'B_Mean',\n",
    "       'B_STD', 'B_MED', 'Canny', 'ORB_X', 'ORB_Y',]\n",
    "X_train = data_train[predictors]\n",
    "X_test = data_test[predictors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(220, 220)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(X_train.columns): \n",
    "    column = v\n",
    "    X_train[str(column)] = X_train[str(column)].astype(float)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = y_train.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_constant= sm.add_constant(X_train)\n",
    "X_test_constant= sm.add_constant(X_test)\n",
    "\n",
    "#MODEL = sm.OLS(y_train.astype(float), X_train_constant.astype(float)).fit()\n",
    "#results = model_train.fit()\n",
    "\n",
    "model = sm.OLS(np.asarray((y_train)), np.asarray((X_train))).fit()\n",
    "predictions = model.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1439929957948708, -0.04782148068336611)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lm = linear_model.LinearRegression() \n",
    "model = lm.fit(X_train,y_train) \n",
    "predictions = lm.predict(X_train)\n",
    "\n",
    "model.score(X_train,y_train), model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RidgeCV(alphas=[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000], cv=10,\n",
      "    fit_intercept=True, gcv_mode=None, normalize=False, scoring=None,\n",
      "    store_cv_values=False)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.1414840209879603, 0.0010873433083060657)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha= [10**-5, 10**-4, 10**-3, 10**-2, 10**-1, 10**0, 10**1, 10**2,10**3, ]\n",
    "ridge = RidgeCV(alphas=alpha, cv=10, fit_intercept=True)\n",
    "ridge.fit(X_train, y_train)\n",
    "print(ridge.fit(X_train, y_train))\n",
    "ridge.score(X_train, y_train), ridge.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.1414840209879603, 0.0010873433083060657)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge.score(X_train, y_train), ridge.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoCV(alphas=[1e-05, 0.0001, 0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
      "    copy_X=True, cv=10, eps=0.001, fit_intercept=True, max_iter=10000,\n",
      "    n_alphas=100, n_jobs=1, normalize=False, positive=False,\n",
      "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
      "    verbose=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "##\n",
    "lasso = LassoCV(alphas=alpha, cv=10, max_iter=10000, fit_intercept=True)\n",
    "print(lasso.fit(X_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, -0.0010378470514764704)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_train, y_train), lasso.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "for i,v in enumerate([1,2,3,4,5]): \n",
    "    \n",
    "    a = PolynomialFeatures(v)\n",
    "    modelo2 = make_pipeline(a, LinearRegression())\n",
    "    model_for_list2 = modelo2.fit(X_train, y_train)\n",
    "    r2 = r2_score(y_train, model_for_list2.predict(X_train))\n",
    "    r2_test = r2_score(y_test, model_for_list2.predict(X_test))\n",
    "    print(v, \"train : \", r2)\n",
    "    print(v, \"test : \", r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 train :  0.0\n",
      "1 test :  -0.0010378470514764704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 train :  0.020577097385743093\n",
      "2 test :  0.03522576768893704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 train :  0.6211280301068582\n",
      "3 test :  -0.7090386256544925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b98294461b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodelo2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlasso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmodel_for_list2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_for_list2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mr2_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_for_list2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1190\u001b[0m                 for train, test in folds)\n\u001b[1;32m   1191\u001b[0m         mse_paths = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0;32m-> 1192\u001b[0;31m                              backend=\"threading\")(jobs)\n\u001b[0m\u001b[1;32m   1193\u001b[0m         \u001b[0mmse_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_l1_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0mmean_mse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, train, test, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;31m# X is copied and a reference is kept here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'csc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m     \u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpath_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36mlasso_path\u001b[0;34m(X, y, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, **params)\u001b[0m\n\u001b[1;32m    263\u001b[0m                      \u001b[0malphas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                      \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m                      positive=positive, return_n_iter=return_n_iter, **params)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/python3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py\u001b[0m in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    475\u001b[0m             model = cd_fast.enet_coordinate_descent(\n\u001b[1;32m    476\u001b[0m                 \u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml2_reg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m                 positive)\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             raise ValueError(\"Precompute should be one of True, False, \"\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "for i,v in enumerate([1,2,3,4,5]):     \n",
    "    a = PolynomialFeatures(v)\n",
    "    modelo2 = make_pipeline(a, lasso)\n",
    "    model_for_list2 = modelo2.fit(X_train, y_train)\n",
    "    r2 = r2_score(y_train, model_for_list2.predict(X_train))\n",
    "    r2_test = r2_score(y_test, model_for_list2.predict(X_test))\n",
    "    print(v, \"train : \", r2)\n",
    "    print(v, \"test : \", r2_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT, Lasso, Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### WP NOTES \n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import normalize, MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "y = df.final_score\n",
    "\n",
    "predictors = ['R_Mean', 'R_STD', 'R_MED', 'G_Mean', 'G_STD', 'G_MED', 'B_Mean',\n",
    "       'B_STD', 'B_MED', 'Canny', 'ORB_X', 'ORB_Y',]\n",
    "X = df[predictors]\n",
    "\n",
    "#X = normalize(X, axis=0)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "print(X.shape)\n",
    "\n",
    "poly = PolynomialFeatures(4) \n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=9)\n",
    "print(X_train.shape)\n",
    "\n",
    "#l_model = Lasso(alpha=0.001)\n",
    "l_model = DecisionTreeRegressor(max_depth=2)\n",
    "l_model.fit(X_train, y_train)\n",
    "print(y_train)\n",
    "print(l_model.score(X_train, y_train))\n",
    "print(l_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(297, 12)\n",
      "(178, 1820)\n",
      "265   -0.660599\n",
      "174    3.521959\n",
      "26     3.521959\n",
      "2      3.521959\n",
      "21     3.521959\n",
      "13     3.521959\n",
      "116    3.521959\n",
      "162    3.521959\n",
      "131    3.521959\n",
      "148    3.521959\n",
      "86     3.521959\n",
      "175    3.521959\n",
      "273   -0.215174\n",
      "28     3.521959\n",
      "55     3.521959\n",
      "47     3.521959\n",
      "190    3.521959\n",
      "107    3.521959\n",
      "293   -0.215174\n",
      "25     3.521959\n",
      "97     3.521959\n",
      "146    3.521959\n",
      "79     3.521959\n",
      "11     3.521959\n",
      "142    3.521959\n",
      "138    3.521959\n",
      "225    3.521959\n",
      "283   -0.215174\n",
      "67     3.521959\n",
      "189    3.521959\n",
      "         ...   \n",
      "285   -0.215174\n",
      "205    3.521959\n",
      "58     3.521959\n",
      "141    3.521959\n",
      "49     3.521959\n",
      "208    3.521959\n",
      "137    3.521959\n",
      "119    3.521959\n",
      "227    3.521959\n",
      "129    3.521959\n",
      "184    3.521959\n",
      "214    3.521959\n",
      "274   -0.215174\n",
      "12     3.521959\n",
      "120    3.521959\n",
      "234    3.521959\n",
      "187    3.521959\n",
      "238    3.521959\n",
      "221    3.521959\n",
      "117    3.521959\n",
      "248    3.521959\n",
      "241    3.521959\n",
      "250    3.521959\n",
      "59     3.521959\n",
      "22     3.521959\n",
      "65     3.521959\n",
      "125    3.521959\n",
      "251    3.521959\n",
      "56     3.521959\n",
      "126    3.521959\n",
      "Name: final_score, Length: 178, dtype: float64\n",
      "0.42423120644403994\n",
      "-0.4080455524455946\n"
     ]
    }
   ],
   "source": [
    "#### WP NOTES \n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "\n",
    "y = df.final_score\n",
    "\n",
    "predictors = ['R_Mean', 'R_STD', 'R_MED', 'G_Mean', 'G_STD', 'G_MED', 'B_Mean',\n",
    "       'B_STD', 'B_MED', 'Canny', 'ORB_X', 'ORB_Y',]\n",
    "X = df[predictors]\n",
    "\n",
    "X = normalize(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "poly = PolynomialFeatures(4) \n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(X_train.shape)\n",
    "\n",
    "l_model = Lasso(alpha=10.)\n",
    "l_model.fit(X_train, y_train)\n",
    "print(l_model.score(X_train, y_train))\n",
    "print(l_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### WP NOTES \n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import normalize \n",
    "\n",
    "\n",
    "y = df.final_score\n",
    "\n",
    "predictors = ['R_Mean', 'R_STD', 'R_MED', 'G_Mean', 'G_STD', 'G_MED', 'B_Mean',\n",
    "       'B_STD', 'B_MED', 'Canny', 'ORB_X', 'ORB_Y',]\n",
    "X = df[predictors]\n",
    "\n",
    "X = normalize(X, axis=0)\n",
    "print(X.shape)\n",
    "\n",
    "poly = PolynomialFeatures(4) \n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(X_train.shape)\n",
    "\n",
    "l_model = Ridge(alpha=10.)\n",
    "l_model.fit(X_train, y_train)\n",
    "print(l_model.score(X_train, y_train))\n",
    "print(l_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.36932041,  0.54743859,  2.08215054,  0.9218996 ,  1.35489945,\n",
       "         4.5410607 ,  1.35229693,  6.34075758,  5.55157387, 11.13021377],\n",
       "       [ 2.09952354,  1.00761317,  4.55590726,  4.83921486,  2.65081373,\n",
       "        10.23757292,  2.39028854,  8.08110628,  6.17255905, 14.43877083],\n",
       "       [ 3.78202257,  1.34615864,  4.33469987,  6.31072484,  4.77796531,\n",
       "        12.7864636 ,  4.2435499 ,  8.64824713,  6.16172524, 22.50252867],\n",
       "       [ 5.48213297,  1.73116615,  4.30778818,  7.20135006,  6.29238961,\n",
       "        13.96667881,  6.57457755, 11.40166137,  6.54458065, 29.88135656],\n",
       "       [ 7.07134538,  1.86377504,  4.24083359,  7.036417  ,  6.99955422,\n",
       "        14.77109688,  7.95823933, 12.99982475,  7.15166986, 30.33783082],\n",
       "       [ 8.31970964,  1.93666605,  4.28037181,  7.33327395,  7.47213781,\n",
       "        15.60594864,  8.81226824, 13.57803514,  7.64750211, 31.19737441],\n",
       "       [ 9.45921245,  2.00052206,  4.27941434,  7.97283969,  8.05708828,\n",
       "        16.57541683,  9.42493848, 13.42502021,  8.17884599, 32.73567685],\n",
       "       [10.46260782,  2.07789108,  4.27817585,  8.70951812,  8.68980787,\n",
       "        17.36752894,  9.77476125, 12.94298538,  8.55116952, 34.69454936],\n",
       "       [11.34272676,  2.17251412,  4.30019213,  9.53523178,  9.3304078 ,\n",
       "        17.82341569, 10.02286541, 12.48345161,  8.79673706, 36.82776719]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.mse_path_  ## mse to r^2  --> this is for the ten fold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,v in enumerate([1,2,3,4,5]):     \n",
    "    a = PolynomialFeatures(v)\n",
    "    modelo2 = make_pipeline(a, ridge)\n",
    "    model_for_list2 = modelo2.fit(X_train, y_train)\n",
    "    r2 = r2_score(y_train, model_for_list2.predict(X_train))\n",
    "    r2_test = r2_score(y_test, model_for_list2.predict(X_test))\n",
    "    print(v, \"train : \", r2)\n",
    "    print(v, \"test : \", r2_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
