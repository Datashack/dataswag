{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.6/site-packages/skimage/viewer/utils/core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import glob\n",
    "import keras\n",
    "import tqdm\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Activation\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import utils\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define File-Path to Users Folder\n",
    "folder_list = ['#foodporn',\"#nightlife\",\"#cosmetics\",\"#rockclimbing\"]\n",
    "image_path = \"/Users/kmotwani/Desktop/Me/Education/Courses/Capstone Project/Google Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#foodporn \n",
      "\n",
      "#nightlife \n",
      "\n",
      "#cosmetics \n",
      "\n",
      "#rockclimbing \n",
      "\n",
      "Number of images loaded: 4000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>File</th>\n",
       "      <th>Image</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...Siempre quise ser grande para poder comerme...</td>\n",
       "      <td>2018-04-08_21-17-49_UTC.jpg</td>\n",
       "      <td>[[[82, 68, 59], [88, 85, 96], [128, 104, 80], ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lonche de Panela By @mojito.restobar . . . #va...</td>\n",
       "      <td>2018-04-08_21-36-39_UTC.jpg</td>\n",
       "      <td>[[[165, 158, 199], [162, 155, 196], [167, 159,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brunching with friends is the best way to spen...</td>\n",
       "      <td>2018-04-08_20-19-50_UTC.jpg</td>\n",
       "      <td>[[[61, 51, 49], [48, 37, 31], [153, 149, 166],...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obsessed with their little stoves. Ordered the...</td>\n",
       "      <td>2018-02-02_15-27-17_UTC.jpg</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hoje para o jantar foram dois ovos, em cima de...</td>\n",
       "      <td>2018-04-08_21-36-29_UTC.jpg</td>\n",
       "      <td>[[[147, 163, 160], [152, 163, 155], [131, 101,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption  \\\n",
       "0  ...Siempre quise ser grande para poder comerme...   \n",
       "1  Lonche de Panela By @mojito.restobar . . . #va...   \n",
       "2  Brunching with friends is the best way to spen...   \n",
       "3  Obsessed with their little stoves. Ordered the...   \n",
       "4  Hoje para o jantar foram dois ovos, em cima de...   \n",
       "\n",
       "                          File  \\\n",
       "0  2018-04-08_21-17-49_UTC.jpg   \n",
       "1  2018-04-08_21-36-39_UTC.jpg   \n",
       "2  2018-04-08_20-19-50_UTC.jpg   \n",
       "3  2018-02-02_15-27-17_UTC.jpg   \n",
       "4  2018-04-08_21-36-29_UTC.jpg   \n",
       "\n",
       "                                               Image  Response  \n",
       "0  [[[82, 68, 59], [88, 85, 96], [128, 104, 80], ...         0  \n",
       "1  [[[165, 158, 199], [162, 155, 196], [167, 159,...         0  \n",
       "2  [[[61, 51, 49], [48, 37, 31], [153, 149, 166],...         0  \n",
       "3  [[[255, 255, 255], [255, 255, 255], [255, 255,...         0  \n",
       "4  [[[147, 163, 160], [152, 163, 155], [131, 101,...         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Helper Function to get images from path\n",
    "def get_df(path, list_input, thresh):\n",
    "    final_list = []\n",
    "    for ind, i in enumerate(list_input):\n",
    "        temp_path = path + i\n",
    "        print(i,\"\\n\")\n",
    "        count = 0\n",
    "        for j in glob.glob(temp_path + '/*.jpg'):\n",
    "            temp_dict = {}\n",
    "            file_name = j.replace(temp_path,'')[1:]\n",
    "            img = image.load_img(j, target_size=(128, 128))\n",
    "            try:\n",
    "                with open(temp_path+\"/\"+file_name[:-4]+'.txt', encoding=\"utf-8\") as f:\n",
    "                    content = f.readlines()\n",
    "                    caption = ' '.join([x.strip() for x in content])\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            temp_dict['File'], temp_dict['Response'] = file_name, int(ind)\n",
    "            temp_dict['Image'], temp_dict['Caption'] = np.array(img), caption\n",
    "            final_list.append(temp_dict)\n",
    "            count += 1\n",
    "            if count==thresh:\n",
    "                break\n",
    "    return pd.DataFrame(final_list) \n",
    "\n",
    "\n",
    "#Get Images from User List and Path\n",
    "df = get_df(image_path, folder_list, 1000)\n",
    "print(\"Number of images loaded:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split train and test set\n",
    "use_df = df.sample(frac=1).reset_index(drop=True)\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(use_df)) < 0.7\n",
    "total_data_train = use_df[msk]\n",
    "total_data_test = use_df[~msk]\n",
    "\n",
    "#Define X,Y\n",
    "x_train = np.array([i for i in total_data_train['Image'].as_matrix()])\n",
    "x_test = np.array([i for i in total_data_test['Image'].as_matrix()])\n",
    "y_train = utils.to_categorical(total_data_train['Response'].as_matrix(), num_classes=4)\n",
    "y_test = utils.to_categorical(total_data_test['Response'].as_matrix(), num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to create CNN Model for Image Classification\n",
    "def createModel(shape, classes_count):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (5, 5), input_shape=(128, 128, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5), activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(classes_count, activation='softmax'))\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#Helper function to run model and save intermediate weights\n",
    "def run_model(model, x_train, y_train, x_test, y_test, batch_size, epochs):\n",
    "    model.compile(loss='categorical_crossentropy',optimizer=keras.optimizers.Adam(lr=1e-4),metrics=['accuracy'])\n",
    "    filepath=\"Saved_Models/KRM_weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    check = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period = 10)\n",
    "    callbacks_list = [check]\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                       validation_data=(x_test, y_test), callbacks=callbacks_list)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 124, 124, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 58, 58, 32)        25632     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 29, 29, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 25, 64)        51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 1,259,620\n",
      "Trainable params: 1,259,620\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 2791 samples, validate on 1209 samples\n",
      "Epoch 1/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 10.6092 - acc: 0.2730 - val_loss: 8.8362 - val_acc: 0.3160\n",
      "Epoch 2/2000\n",
      "2791/2791 [==============================] - 95s 34ms/step - loss: 10.0240 - acc: 0.3071 - val_loss: 8.9848 - val_acc: 0.3342\n",
      "Epoch 3/2000\n",
      "2791/2791 [==============================] - 94s 34ms/step - loss: 9.0104 - acc: 0.3475 - val_loss: 6.7404 - val_acc: 0.4276\n",
      "Epoch 4/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 8.1032 - acc: 0.3809 - val_loss: 5.3042 - val_acc: 0.5095\n",
      "Epoch 5/2000\n",
      "2791/2791 [==============================] - 90s 32ms/step - loss: 6.2416 - acc: 0.4583 - val_loss: 4.6012 - val_acc: 0.5029\n",
      "Epoch 6/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 4.5660 - acc: 0.4808 - val_loss: 2.9499 - val_acc: 0.4888\n",
      "Epoch 7/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 2.6420 - acc: 0.4679 - val_loss: 1.4706 - val_acc: 0.4731\n",
      "Epoch 8/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.4650 - acc: 0.4414 - val_loss: 1.2934 - val_acc: 0.4293\n",
      "Epoch 9/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 1.3161 - acc: 0.3970 - val_loss: 1.3163 - val_acc: 0.4243\n",
      "Epoch 10/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.3198 - acc: 0.3916 - val_loss: 1.3015 - val_acc: 0.4442\n",
      "\n",
      "Epoch 00010: val_acc improved from -inf to 0.44417, saving model to Saved_Models/KRM_weights-10-0.44.hdf5\n",
      "Epoch 11/2000\n",
      "2791/2791 [==============================] - 94s 34ms/step - loss: 1.2865 - acc: 0.4181 - val_loss: 1.2827 - val_acc: 0.4458\n",
      "Epoch 12/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 1.2553 - acc: 0.4300 - val_loss: 1.2632 - val_acc: 0.4648\n",
      "Epoch 13/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 1.2362 - acc: 0.4572 - val_loss: 1.2333 - val_acc: 0.4905\n",
      "Epoch 14/2000\n",
      "2791/2791 [==============================] - 96s 34ms/step - loss: 1.1868 - acc: 0.4776 - val_loss: 1.2125 - val_acc: 0.5070\n",
      "Epoch 15/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.1582 - acc: 0.5109 - val_loss: 1.1974 - val_acc: 0.5178\n",
      "Epoch 16/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 1.1384 - acc: 0.4984 - val_loss: 1.1797 - val_acc: 0.5343\n",
      "Epoch 17/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 1.1130 - acc: 0.5245 - val_loss: 1.1696 - val_acc: 0.5376\n",
      "Epoch 18/2000\n",
      "2791/2791 [==============================] - 91s 32ms/step - loss: 1.0834 - acc: 0.5288 - val_loss: 1.1741 - val_acc: 0.5360\n",
      "Epoch 19/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.0766 - acc: 0.5399 - val_loss: 1.1576 - val_acc: 0.5376\n",
      "Epoch 20/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.0657 - acc: 0.5417 - val_loss: 1.1539 - val_acc: 0.5261\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.44417 to 0.52605, saving model to Saved_Models/KRM_weights-20-0.53.hdf5\n",
      "Epoch 21/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 1.0317 - acc: 0.5554 - val_loss: 1.1511 - val_acc: 0.5509\n",
      "Epoch 22/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.0068 - acc: 0.5675 - val_loss: 1.1420 - val_acc: 0.5467\n",
      "Epoch 23/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 1.0131 - acc: 0.5711 - val_loss: 1.1338 - val_acc: 0.5484\n",
      "Epoch 24/2000\n",
      "2791/2791 [==============================] - 87s 31ms/step - loss: 0.9670 - acc: 0.5747 - val_loss: 1.1457 - val_acc: 0.5492\n",
      "Epoch 25/2000\n",
      "2791/2791 [==============================] - 87s 31ms/step - loss: 0.9448 - acc: 0.5962 - val_loss: 1.1311 - val_acc: 0.5616\n",
      "Epoch 26/2000\n",
      "2791/2791 [==============================] - 87s 31ms/step - loss: 0.9335 - acc: 0.6016 - val_loss: 1.1377 - val_acc: 0.5542\n",
      "Epoch 27/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 0.9116 - acc: 0.6087 - val_loss: 1.1404 - val_acc: 0.5476\n",
      "Epoch 28/2000\n",
      "2791/2791 [==============================] - 90s 32ms/step - loss: 0.8816 - acc: 0.6281 - val_loss: 1.1276 - val_acc: 0.5583\n",
      "Epoch 29/2000\n",
      "2791/2791 [==============================] - 90s 32ms/step - loss: 0.8705 - acc: 0.6392 - val_loss: 1.1356 - val_acc: 0.5600\n",
      "Epoch 30/2000\n",
      "2791/2791 [==============================] - 90s 32ms/step - loss: 0.8506 - acc: 0.6396 - val_loss: 1.1391 - val_acc: 0.5600\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.52605 to 0.55997, saving model to Saved_Models/KRM_weights-30-0.56.hdf5\n",
      "Epoch 31/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 0.8368 - acc: 0.6360 - val_loss: 1.1371 - val_acc: 0.5658\n",
      "Epoch 32/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 0.8251 - acc: 0.6406 - val_loss: 1.1612 - val_acc: 0.5691\n",
      "Epoch 33/2000\n",
      "2791/2791 [==============================] - 90s 32ms/step - loss: 0.8017 - acc: 0.6553 - val_loss: 1.1345 - val_acc: 0.5732\n",
      "Epoch 34/2000\n",
      "2791/2791 [==============================] - 90s 32ms/step - loss: 0.7813 - acc: 0.6618 - val_loss: 1.1446 - val_acc: 0.5724\n",
      "Epoch 35/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 0.7470 - acc: 0.6951 - val_loss: 1.1496 - val_acc: 0.5691\n",
      "Epoch 36/2000\n",
      "2791/2791 [==============================] - 91s 33ms/step - loss: 0.7412 - acc: 0.6840 - val_loss: 1.1356 - val_acc: 0.5823\n",
      "Epoch 37/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 0.7202 - acc: 0.6922 - val_loss: 1.1910 - val_acc: 0.5740\n",
      "Epoch 38/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 0.7184 - acc: 0.6944 - val_loss: 1.1630 - val_acc: 0.5848\n",
      "Epoch 39/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 0.6850 - acc: 0.7051 - val_loss: 1.1645 - val_acc: 0.5848\n",
      "Epoch 40/2000\n",
      "2791/2791 [==============================] - 92s 33ms/step - loss: 0.6548 - acc: 0.7259 - val_loss: 1.1877 - val_acc: 0.5840\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.55997 to 0.58395, saving model to Saved_Models/KRM_weights-40-0.58.hdf5\n",
      "Epoch 41/2000\n",
      "2791/2791 [==============================] - 93s 33ms/step - loss: 0.6527 - acc: 0.7177 - val_loss: 1.1762 - val_acc: 0.5823\n",
      "Epoch 42/2000\n",
      "2791/2791 [==============================] - 94s 34ms/step - loss: 0.6290 - acc: 0.7338 - val_loss: 1.1846 - val_acc: 0.5806\n",
      "Epoch 43/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2791/2791 [==============================] - 102s 36ms/step - loss: 0.6140 - acc: 0.7324 - val_loss: 1.1753 - val_acc: 0.5864\n",
      "Epoch 44/2000\n",
      "2791/2791 [==============================] - 100s 36ms/step - loss: 0.5944 - acc: 0.7510 - val_loss: 1.1967 - val_acc: 0.5914\n",
      "Epoch 45/2000\n",
      "2791/2791 [==============================] - 96s 34ms/step - loss: 0.5852 - acc: 0.7506 - val_loss: 1.2023 - val_acc: 0.5964\n",
      "Epoch 46/2000\n",
      "2791/2791 [==============================] - 84s 30ms/step - loss: 0.5691 - acc: 0.7635 - val_loss: 1.2133 - val_acc: 0.5848\n",
      "Epoch 47/2000\n",
      "2791/2791 [==============================] - 251s 90ms/step - loss: 0.5531 - acc: 0.7718 - val_loss: 1.2328 - val_acc: 0.5873\n",
      "Epoch 48/2000\n",
      "2791/2791 [==============================] - 1747s 626ms/step - loss: 0.5314 - acc: 0.7836 - val_loss: 1.2481 - val_acc: 0.5922\n",
      "Epoch 49/2000\n",
      "1536/2791 [===============>..............] - ETA: 36s - loss: 0.5464 - acc: 0.7832"
     ]
    }
   ],
   "source": [
    "#Create and Run model\n",
    "model = createModel((128,128,3), 4)\n",
    "run_model(model, x_train, y_train, x_test, y_test, batch_size=512, epochs=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for ind,i in enumerate(x_train):\n",
    "    count+=1\n",
    "    if count<10:\n",
    "        plt.figure()\n",
    "        plt.imshow(i)\n",
    "        print(y_train[ind])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
