{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define List of Users and define File-Path to Users Folder\n",
    "list_users = ['ana_brandine', 'vicky_regouli', 'luismiguelpss', 'ilariabiagini', \n",
    "              'emnegg', 'kerendhahn', 'agiorgina', 'roulamatta', 'jussbieber9827', \n",
    "              'eremiaheidr', 'eunhuiheo', 'anastasiakaps', 'achaelilsone', 'orit_talbi',\n",
    "              'sorayaalassmi', 'altonolnlis', 'vaso1977', 'theunrealobserver', 'nsb.koc',\n",
    "              'vivpeng', 'amrynevillek', 'danalev7', 'irienyree', 'lilachturgeman', \n",
    "              'emel_karakoc', 'thiswhomustbekept', 'j_f_lil', 'ulietteearneye', \n",
    "              'gilanaz', 'sarrahdolly', 'alexchahine97', 'photographerarson', \n",
    "              'angecanindo', 'fiona_smithson', 'chelsea_xu620']\n",
    "\n",
    "path = \"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/Datasets/sample_users_media/\"\n",
    "dest_path = \"/Users/kmotwani/Desktop/Me - Local/Education/Courses/Capstone Project/Clustering_kNN_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function to get images from path\n",
    "def get_images(path, list_users):\n",
    "    #Get all Images of Users in the List\n",
    "    user_imgs = {}\n",
    "    for i in list_users:\n",
    "        temp_path = path + i\n",
    "        for j in glob.glob(temp_path + '/*.jpg'):\n",
    "            file_name = j.replace(temp_path,'')[1:]\n",
    "            img = io.imread(j)\n",
    "            user_imgs[(i,file_name)] = img\n",
    "    return user_imgs \n",
    "\n",
    "\n",
    "#Get Images from User List and Path\n",
    "user_imgs = get_images(path, list_users)\n",
    "print(\"Number of images loaded:\", len(user_imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to convert image to d-dimension vector\n",
    "def convert(user_imgs):\n",
    "    user_features = []\n",
    "    for i in user_imgs.items():\n",
    "        r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "        g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "        b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "        canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "        try:\n",
    "            orb = cv2.ORB_create(100)\n",
    "            kp = orb.detect(i[1],None)\n",
    "            kp, des = orb.compute(i[1], kp)\n",
    "            orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "            orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "        except ValueError:\n",
    "            continue\n",
    "        user_features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "    return user_features\n",
    "    \n",
    "#Convert Images\n",
    "user_features = convert(user_imgs)\n",
    "print(\"Feature Vectors Created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataframe of Features\n",
    "df = pd.DataFrame(user_features)\n",
    "df.columns = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Define Cluster Count\n",
    "cluster_count = 4\n",
    "\n",
    "#Define Dataset\n",
    "data = df.copy(deep=True)\n",
    "del data[\"User_Handle\"]\n",
    "del data[\"URL\"]\n",
    "display(data.head())\n",
    "\n",
    "#Implement Gaussian Mixture Model Algortihm \n",
    "model_gaussian = GaussianMixture(n_components=cluster_count, random_state=9001)\n",
    "\n",
    "#Fit Model and Predict\n",
    "model_gaussian.fit(data)\n",
    "y_pred = model_gaussian.predict_proba(data)\n",
    "\n",
    "#Add prediction to dataframe     \n",
    "for i in range(0,cluster_count+1):\n",
    "    if i==cluster_count:\n",
    "        label = \"Prediction\"\n",
    "        df[label] = model_gaussian.predict(data)\n",
    "        break\n",
    "    label = \"Prob_\" + str(i)\n",
    "    df[label] = y_pred[:,i]\n",
    "    \n",
    "\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to create folders for Image Clustering\n",
    "def save_clusters(df, user_imgs, dest_path, label):\n",
    "    dest_path += label + \"/\"\n",
    "    for i in user_imgs.items():\n",
    "        temp_row = df[df[\"URL\"]==i[0][1]]\n",
    "        try:\n",
    "            name, pred_folder = i[0][1], str(temp_row['Prediction'].values[0])\n",
    "        except IndexError:\n",
    "            continue\n",
    "        temp_path = dest_path + \"Cluster\" + pred_folder + \"/\"\n",
    "        if not os.path.exists(temp_path):\n",
    "            os.makedirs(temp_path)\n",
    "        io.imsave(temp_path+name, i[1])\n",
    "\n",
    "save_clusters(df, user_imgs, dest_path, \"Competitors\")\n",
    "print(\"All Images Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Helper function to obtain percentage of Cluster Presence\n",
    "def cluster_presence(df):\n",
    "    cluster_presence = []\n",
    "    for i in list(df['User_Handle'].unique()):\n",
    "        user_dict = {}\n",
    "        temp_df = df[df['User_Handle']==i]\n",
    "        post_count  =  len(temp_df)\n",
    "        user_dict['User_Handle'] = i\n",
    "        for j in range(0, cluster_count):\n",
    "            user_dict[\"Cluster_\"+str(j)] = sum(temp_df['Prob_'+str(j)])/post_count\n",
    "        cluster_presence.append(user_dict)\n",
    "    return cluster_presence\n",
    "\n",
    "#Create Cluster Presence Dataframe\n",
    "presence_list = cluster_presence(df)\n",
    "df_presence = pd.DataFrame(presence_list)\n",
    "df_presence = df_presence.fillna(0)\n",
    "display(df_presence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Cluster Count\n",
    "cluster_count = 4\n",
    "\n",
    "#Define Dataset\n",
    "data_presence = df_presence.copy(deep=True)\n",
    "del data_presence[\"User_Handle\"]\n",
    "\n",
    "#Implement K-Means Algortihm\n",
    "model_kmeans_users = KMeans(n_clusters=cluster_count, random_state=9001)\n",
    "\n",
    "#Fit Model and Predict\n",
    "model_kmeans_users.fit(data_presence)\n",
    "print(\"Representative User Vectors:\\n\\n\",model_kmeans_users.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function to get images from target path \n",
    "def get_images_test(path):\n",
    "    #Get all Images of Users in the List\n",
    "    user_imgs = {}\n",
    "    for j in glob.glob(path + '/*.jpg'):\n",
    "        file_name = j.replace(path,'')[1:]\n",
    "        img = io.imread(j)\n",
    "        user_imgs[(\"Target\",file_name)] = img\n",
    "    return user_imgs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define target image folder path\n",
    "target_path = \"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/Images/Test/\"\n",
    "target_dict = get_images_test(target_path)\n",
    "\n",
    "#Convert image to feature vector and define columns\n",
    "target_df = pd.DataFrame(convert(target_dict))\n",
    "target_df.columns = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "\n",
    "#Define Target DF\n",
    "data = target_df.copy(deep=True)\n",
    "del data[\"User_Handle\"]\n",
    "del data[\"URL\"]\n",
    "\n",
    "#Make Prediction\n",
    "y_pred = model_gaussian.predict_proba(data)\n",
    "\n",
    "#Add prediction to dataframe     \n",
    "for i in range(0,cluster_count+1):\n",
    "    if i==cluster_count:\n",
    "        label = \"Prediction\"\n",
    "        target_df[label] = model_gaussian.predict(data)\n",
    "        break\n",
    "    label = \"Prob_\" + str(i)\n",
    "    target_df[label] = y_pred[:,i]\n",
    "\n",
    "display(target_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to generate distance dictionary\n",
    "def get_dist_dict(df, k, model):\n",
    "    final_dict = {}\n",
    "    for i in range(0,len(df)):\n",
    "        temp_file = df.iloc[i,1]\n",
    "        temp_dist = []\n",
    "        for j in range(0, k):\n",
    "            temp_dist.append(np.linalg.norm(df.iloc[i,14:14+k].astype(float)-model.cluster_centers_[j]))\n",
    "        final_dict[temp_file] = temp_dist\n",
    "    return final_dict\n",
    "\n",
    "\n",
    "final = get_dist_dict(target_df, cluster_count, model_kmeans_users)\n",
    "print(final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model_kmeans_users, 'model_kmeans.pkl') \n",
    "del model_kmeans_users\n",
    "model_kmeans_users = joblib.load('model_kmeans.pkl')\n",
    "print(model_kmeans_users.cluster_centers_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ClusteringTrain.py\n"
     ]
    }
   ],
   "source": [
    "%%file ClusteringTrain.py\n",
    "\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class Clustering:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, train_path, save_path):\n",
    "        self.train_path = train_path\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    #Helper Function to get images from train path\n",
    "    def get_train_images(self, user_list):\n",
    "        list_users = user_list\n",
    "        self.train_imgs = {}\n",
    "        for i in list_users:\n",
    "            temp_path = self.train_path + i\n",
    "            for j in glob.glob(temp_path + '/*.jpg'):\n",
    "                file_name = j.replace(temp_path,'')[1:]\n",
    "                img = io.imread(j)\n",
    "                self.train_imgs[(i,file_name)] = img \n",
    "        print(\"Number of images loaded:\", len(self.train_imgs))\n",
    "    \n",
    "    #Helper function to convert image to d-dimension vector for each image and \n",
    "    #return dataframe of all images\n",
    "    def convert_to_features(self, columns):\n",
    "        features = []\n",
    "        for i in self.train_imgs.items():\n",
    "            r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "            g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "            b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "            canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "            try:\n",
    "                orb = cv2.ORB_create(100)\n",
    "                kp = orb.detect(i[1],None)\n",
    "                kp, des = orb.compute(i[1], kp)\n",
    "                orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "                orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "        df = pd.DataFrame(features, columns = columns)\n",
    "        return df\n",
    "    \n",
    "    def model_images_fit(self, df, k, extra_cols, rand_state):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "\n",
    "        #Implement Gaussian Mixture Model Algortihm \n",
    "        model = GaussianMixture(n_components=k, random_state=9001)\n",
    "\n",
    "        #Fit Model and Predict\n",
    "        model.fit(data)\n",
    "        y_pred = model.predict_proba(data)\n",
    "\n",
    "        #Add prediction to dataframe and return \n",
    "        for i in range(0,k+1):\n",
    "            if i==k:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = \"Prob_\" + str(i)\n",
    "            df[label] = y_pred[:,i]\n",
    "        return df, model\n",
    "    \n",
    "    def model_users_fit(self, df, k, extra_cols, rand_state):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "\n",
    "        #Implement K-Means Algortihm\n",
    "        model = KMeans(n_clusters=k, random_state=rand_state)\n",
    "\n",
    "        #Fit Model, Predict and Return\n",
    "        model.fit(data)\n",
    "        y_pred = model.predict(data)\n",
    "        df['Prediction'] = model.labels_\n",
    "        return df, model\n",
    "    \n",
    "    #Helper function to create folders for Image Clustering\n",
    "    def save_clusters(self, df, label):\n",
    "        self.save_path += label + \"/\"\n",
    "        for i in self.train_imgs.items():\n",
    "            temp_row = df[df[\"URL\"]==i[0][1]]\n",
    "            try:\n",
    "                name, pred_folder = i[0][1], str(temp_row['Prediction'].values[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            temp_path = self.save_path + \"Cluster\" + pred_folder + \"/\"\n",
    "            if not os.path.exists(temp_path):\n",
    "                os.makedirs(temp_path)\n",
    "            io.imsave(temp_path+name, i[1])\n",
    "        print(\"All Images Saved.\")\n",
    "            \n",
    "    #Helper function to obtain percentage of Cluster Presence\n",
    "    def get_cluster_presence(self, df, k):\n",
    "        cluster_presence = []\n",
    "        for i in list(df['User_Handle'].unique()):\n",
    "            user_dict = {}\n",
    "            temp_df = df[df['User_Handle']==i]\n",
    "            post_count  =  len(temp_df)\n",
    "            user_dict['User_Handle'] = i\n",
    "            for j in range(0, k):\n",
    "                user_dict[\"Cluster_\"+str(j)] = sum(temp_df['Prob_'+str(j)])/post_count\n",
    "            cluster_presence.append(user_dict)\n",
    "        df_presence = pd.DataFrame(cluster_presence)\n",
    "        df_presence = df_presence.fillna(0)\n",
    "        return df_presence\n",
    "    \n",
    "    #Helper function to save model \n",
    "    def save_model(self, model, path):\n",
    "        joblib.dump(model, path) \n",
    "        print(\"Model Saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ClusteringTest.py\n"
     ]
    }
   ],
   "source": [
    "%%file ClusteringTest.py\n",
    "\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class Ranking:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, target_path):\n",
    "        self.target_path = target_path\n",
    "\n",
    "    #Helper Function to get images from target path \n",
    "    def get_images_target(self):\n",
    "        #Get all Images of Users in the List\n",
    "        self.target_imgs = {}\n",
    "        for j in glob.glob(self.target_path + '/*.jpg'):\n",
    "            file_name = j.replace(self.target_path,'')[:]\n",
    "            img = io.imread(j)\n",
    "            self.target_imgs[(\"Input/Target\",file_name)] = img\n",
    "        print(\"Number of images loaded:\", len(self.target_imgs))\n",
    "    \n",
    "    #Helper function to load saved model\n",
    "    def load_model(self, path):\n",
    "        model = joblib.load(path)\n",
    "        print (\"Model loaded.\")\n",
    "        return model\n",
    "\n",
    "    #Helper function to convert image to d-dimension vector for each image and \n",
    "    #return dataframe of all images\n",
    "    def convert_to_features(self, columns):\n",
    "        features = []\n",
    "        for i in self.target_imgs.items():\n",
    "            r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "            g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "            b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "            canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "            try:\n",
    "                orb = cv2.ORB_create(100)\n",
    "                kp = orb.detect(i[1],None)\n",
    "                kp, des = orb.compute(i[1], kp)\n",
    "                orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "                orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "        df = pd.DataFrame(features, columns = columns)\n",
    "        return df\n",
    "\n",
    "    #Helper function to make prediction for target images using image model\n",
    "    def predict(self, df, model, k, cluster_names, extra_cols):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "            \n",
    "        #Make Prediction\n",
    "        y_pred = model.predict_proba(data)\n",
    "        \n",
    "        #Add prediction to dataframe and return \n",
    "        for i in range(0,k+1):\n",
    "            if i==k:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = cluster_names[i] + \" (\" + str(i) + \")\"\n",
    "            df[label] = y_pred[:,i]\n",
    "        return df\n",
    "    \n",
    "    #Helper function to generate distance dictionary\n",
    "    def get_result(self, df, k, model):\n",
    "        final_dict = {}\n",
    "        for i in range(0,len(df)):\n",
    "            temp_file = df.iloc[i,1]\n",
    "            temp_dist = []\n",
    "            for j in range(0, k):\n",
    "                temp_dist.append(np.linalg.norm(df.iloc[i,14:14+k].astype(float)-model.cluster_centers_[j]))\n",
    "            final_dict[temp_file] = temp_dist\n",
    "        return final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/skimage/viewer/utils/core.py:10: UserWarning: Recommended matplotlib backend is `Agg` for full skimage.viewer functionality.\n",
      "  warn(\"Recommended matplotlib backend is `Agg` for full \"\n"
     ]
    }
   ],
   "source": [
    "import ClusteringTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths\n",
    "train_path = \"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/Datasets/sample_users_media/\"\n",
    "dest_path = \"/Users/kmotwani/Desktop/Me - Local/Education/Courses/Capstone Project/Clustering_\"\n",
    "\n",
    "#Create Object\n",
    "obj_train = ClusteringTrain.Clustering(train_path, dest_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 887\n"
     ]
    }
   ],
   "source": [
    "#Define User List\n",
    "#user_list = ['ana_brandine', 'vicky_regouli', 'luismiguelpss', 'ilariabiagini', \n",
    "#              'emnegg', 'kerendhahn', 'agiorgina', 'roulamatta', 'jussbieber9827', \n",
    "#              'eremiaheidr', 'eunhuiheo', 'anastasiakaps', 'achaelilsone', 'orit_talbi',\n",
    "#              'sorayaalassmi', 'altonolnlis', 'vaso1977', 'theunrealobserver', 'nsb.koc',\n",
    "#              'vivpeng', 'amrynevillek', 'danalev7', 'irienyree', 'lilachturgeman', \n",
    "#              'emel_karakoc', 'thiswhomustbekept', 'j_f_lil', 'ulietteearneye', \n",
    "#              'gilanaz', 'sarrahdolly', 'alexchahine97', 'photographerarson', \n",
    "#              'angecanindo', 'fiona_smithson', 'chelsea_xu620']\n",
    "\n",
    "user_list = ['sarrahdolly', 'alexchahine97', 'photographerarson', 'chelsea_xu620']\n",
    "\n",
    "#Get Train Images\n",
    "obj_train.get_train_images(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Handle</th>\n",
       "      <th>URL</th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>19367624_101179547177951_1390150557162799104_n...</td>\n",
       "      <td>60.54667718272289</td>\n",
       "      <td>42.19724092944082</td>\n",
       "      <td>46.0</td>\n",
       "      <td>115.95750487329434</td>\n",
       "      <td>32.60043756841384</td>\n",
       "      <td>116.0</td>\n",
       "      <td>154.99817379706576</td>\n",
       "      <td>59.84647423921173</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.985707140658665</td>\n",
       "      <td>164.9659097623957</td>\n",
       "      <td>111.04306045532226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>11875280_1178056292210579_2092095415_n.jpg</td>\n",
       "      <td>184.04617877492876</td>\n",
       "      <td>35.35372396838029</td>\n",
       "      <td>195.0</td>\n",
       "      <td>161.45551994301994</td>\n",
       "      <td>68.04532270297828</td>\n",
       "      <td>189.0</td>\n",
       "      <td>171.04471866096867</td>\n",
       "      <td>57.410411921227386</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.13616452991453</td>\n",
       "      <td>168.73200391928353</td>\n",
       "      <td>91.83816484715389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>10735461_1407215272901698_149677391_n.jpg</td>\n",
       "      <td>81.98706787109376</td>\n",
       "      <td>53.23458707440772</td>\n",
       "      <td>78.0</td>\n",
       "      <td>64.063896484375</td>\n",
       "      <td>43.261115626473355</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.79611328125</td>\n",
       "      <td>33.462023024518665</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.42938232421875</td>\n",
       "      <td>75.28755110353232</td>\n",
       "      <td>138.2118056935072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>11850363_502039876616776_1969297340_n.jpg</td>\n",
       "      <td>154.0544828402367</td>\n",
       "      <td>59.84234337996732</td>\n",
       "      <td>163.0</td>\n",
       "      <td>140.04713372781066</td>\n",
       "      <td>66.63991410840953</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.46451360946745</td>\n",
       "      <td>70.77093845686376</td>\n",
       "      <td>142.0</td>\n",
       "      <td>37.09902958579882</td>\n",
       "      <td>79.52617734938403</td>\n",
       "      <td>106.16357121805042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>25017868_725944580942040_944431130495418368_n.jpg</td>\n",
       "      <td>200.38099865768135</td>\n",
       "      <td>57.38725202538483</td>\n",
       "      <td>221.0</td>\n",
       "      <td>141.86143299364454</td>\n",
       "      <td>72.7586487745246</td>\n",
       "      <td>159.0</td>\n",
       "      <td>105.58023641244795</td>\n",
       "      <td>66.37926170123202</td>\n",
       "      <td>96.0</td>\n",
       "      <td>16.535112590401052</td>\n",
       "      <td>95.47079070813558</td>\n",
       "      <td>215.38616946326357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_Handle                                                URL  \\\n",
       "0  sarrahdolly  19367624_101179547177951_1390150557162799104_n...   \n",
       "1  sarrahdolly         11875280_1178056292210579_2092095415_n.jpg   \n",
       "2  sarrahdolly          10735461_1407215272901698_149677391_n.jpg   \n",
       "3  sarrahdolly          11850363_502039876616776_1969297340_n.jpg   \n",
       "4  sarrahdolly  25017868_725944580942040_944431130495418368_n.jpg   \n",
       "\n",
       "               R_Mean              R_STD  R_MED              G_Mean  \\\n",
       "0   60.54667718272289  42.19724092944082   46.0  115.95750487329434   \n",
       "1  184.04617877492876  35.35372396838029  195.0  161.45551994301994   \n",
       "2   81.98706787109376  53.23458707440772   78.0     64.063896484375   \n",
       "3   154.0544828402367  59.84234337996732  163.0  140.04713372781066   \n",
       "4  200.38099865768135  57.38725202538483  221.0  141.86143299364454   \n",
       "\n",
       "                G_STD  G_MED              B_Mean               B_STD  B_MED  \\\n",
       "0   32.60043756841384  116.0  154.99817379706576   59.84647423921173  183.0   \n",
       "1   68.04532270297828  189.0  171.04471866096867  57.410411921227386  193.0   \n",
       "2  43.261115626473355   56.0      67.79611328125  33.462023024518665   61.0   \n",
       "3   66.63991410840953  146.0  140.46451360946745   70.77093845686376  142.0   \n",
       "4    72.7586487745246  159.0  105.58023641244795   66.37926170123202   96.0   \n",
       "\n",
       "                Canny               ORB_X               ORB_Y  \n",
       "0  10.985707140658665   164.9659097623957  111.04306045532226  \n",
       "1   40.13616452991453  168.73200391928353   91.83816484715389  \n",
       "2   12.42938232421875   75.28755110353232   138.2118056935072  \n",
       "3   37.09902958579882   79.52617734938403  106.16357121805042  \n",
       "4  16.535112590401052   95.47079070813558  215.38616946326357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get train dataframe\n",
    "train_df_cols = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "\n",
    "train_df = obj_train.convert_to_features(train_df_cols)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define cluster count for users and images \n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Handle</th>\n",
       "      <th>URL</th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "      <th>Prob_0</th>\n",
       "      <th>Prob_1</th>\n",
       "      <th>Prob_2</th>\n",
       "      <th>Prob_3</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>19367624_101179547177951_1390150557162799104_n...</td>\n",
       "      <td>60.54667718272289</td>\n",
       "      <td>42.19724092944082</td>\n",
       "      <td>46.0</td>\n",
       "      <td>115.95750487329434</td>\n",
       "      <td>32.60043756841384</td>\n",
       "      <td>116.0</td>\n",
       "      <td>154.99817379706576</td>\n",
       "      <td>59.84647423921173</td>\n",
       "      <td>183.0</td>\n",
       "      <td>10.985707140658665</td>\n",
       "      <td>164.9659097623957</td>\n",
       "      <td>111.04306045532226</td>\n",
       "      <td>1.338911e-27</td>\n",
       "      <td>5.819216e-25</td>\n",
       "      <td>0.999976</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>11875280_1178056292210579_2092095415_n.jpg</td>\n",
       "      <td>184.04617877492876</td>\n",
       "      <td>35.35372396838029</td>\n",
       "      <td>195.0</td>\n",
       "      <td>161.45551994301994</td>\n",
       "      <td>68.04532270297828</td>\n",
       "      <td>189.0</td>\n",
       "      <td>171.04471866096867</td>\n",
       "      <td>57.410411921227386</td>\n",
       "      <td>193.0</td>\n",
       "      <td>40.13616452991453</td>\n",
       "      <td>168.73200391928353</td>\n",
       "      <td>91.83816484715389</td>\n",
       "      <td>2.422445e-29</td>\n",
       "      <td>5.413689e-11</td>\n",
       "      <td>0.999993</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>10735461_1407215272901698_149677391_n.jpg</td>\n",
       "      <td>81.98706787109376</td>\n",
       "      <td>53.23458707440772</td>\n",
       "      <td>78.0</td>\n",
       "      <td>64.063896484375</td>\n",
       "      <td>43.261115626473355</td>\n",
       "      <td>56.0</td>\n",
       "      <td>67.79611328125</td>\n",
       "      <td>33.462023024518665</td>\n",
       "      <td>61.0</td>\n",
       "      <td>12.42938232421875</td>\n",
       "      <td>75.28755110353232</td>\n",
       "      <td>138.2118056935072</td>\n",
       "      <td>7.786541e-37</td>\n",
       "      <td>9.992929e-01</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>11850363_502039876616776_1969297340_n.jpg</td>\n",
       "      <td>154.0544828402367</td>\n",
       "      <td>59.84234337996732</td>\n",
       "      <td>163.0</td>\n",
       "      <td>140.04713372781066</td>\n",
       "      <td>66.63991410840953</td>\n",
       "      <td>146.0</td>\n",
       "      <td>140.46451360946745</td>\n",
       "      <td>70.77093845686376</td>\n",
       "      <td>142.0</td>\n",
       "      <td>37.09902958579882</td>\n",
       "      <td>79.52617734938403</td>\n",
       "      <td>106.16357121805042</td>\n",
       "      <td>9.569513e-05</td>\n",
       "      <td>4.251986e-02</td>\n",
       "      <td>0.949140</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>25017868_725944580942040_944431130495418368_n.jpg</td>\n",
       "      <td>200.38099865768135</td>\n",
       "      <td>57.38725202538483</td>\n",
       "      <td>221.0</td>\n",
       "      <td>141.86143299364454</td>\n",
       "      <td>72.7586487745246</td>\n",
       "      <td>159.0</td>\n",
       "      <td>105.58023641244795</td>\n",
       "      <td>66.37926170123202</td>\n",
       "      <td>96.0</td>\n",
       "      <td>16.535112590401052</td>\n",
       "      <td>95.47079070813558</td>\n",
       "      <td>215.38616946326357</td>\n",
       "      <td>2.806121e-20</td>\n",
       "      <td>2.270893e-07</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_Handle                                                URL  \\\n",
       "0  sarrahdolly  19367624_101179547177951_1390150557162799104_n...   \n",
       "1  sarrahdolly         11875280_1178056292210579_2092095415_n.jpg   \n",
       "2  sarrahdolly          10735461_1407215272901698_149677391_n.jpg   \n",
       "3  sarrahdolly          11850363_502039876616776_1969297340_n.jpg   \n",
       "4  sarrahdolly  25017868_725944580942040_944431130495418368_n.jpg   \n",
       "\n",
       "               R_Mean              R_STD  R_MED              G_Mean  \\\n",
       "0   60.54667718272289  42.19724092944082   46.0  115.95750487329434   \n",
       "1  184.04617877492876  35.35372396838029  195.0  161.45551994301994   \n",
       "2   81.98706787109376  53.23458707440772   78.0     64.063896484375   \n",
       "3   154.0544828402367  59.84234337996732  163.0  140.04713372781066   \n",
       "4  200.38099865768135  57.38725202538483  221.0  141.86143299364454   \n",
       "\n",
       "                G_STD  G_MED              B_Mean               B_STD  B_MED  \\\n",
       "0   32.60043756841384  116.0  154.99817379706576   59.84647423921173  183.0   \n",
       "1   68.04532270297828  189.0  171.04471866096867  57.410411921227386  193.0   \n",
       "2  43.261115626473355   56.0      67.79611328125  33.462023024518665   61.0   \n",
       "3   66.63991410840953  146.0  140.46451360946745   70.77093845686376  142.0   \n",
       "4    72.7586487745246  159.0  105.58023641244795   66.37926170123202   96.0   \n",
       "\n",
       "                Canny               ORB_X               ORB_Y        Prob_0  \\\n",
       "0  10.985707140658665   164.9659097623957  111.04306045532226  1.338911e-27   \n",
       "1   40.13616452991453  168.73200391928353   91.83816484715389  2.422445e-29   \n",
       "2   12.42938232421875   75.28755110353232   138.2118056935072  7.786541e-37   \n",
       "3   37.09902958579882   79.52617734938403  106.16357121805042  9.569513e-05   \n",
       "4  16.535112590401052   95.47079070813558  215.38616946326357  2.806121e-20   \n",
       "\n",
       "         Prob_1    Prob_2    Prob_3  Prediction  \n",
       "0  5.819216e-25  0.999976  0.000024           2  \n",
       "1  5.413689e-11  0.999993  0.000007           2  \n",
       "2  9.992929e-01  0.000512  0.000195           1  \n",
       "3  4.251986e-02  0.949140  0.008244           2  \n",
       "4  2.270893e-07  0.999870  0.000130           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fit Model\n",
    "train_df, model_images = obj_train.model_images_fit(train_df, k, [\"User_Handle\",\"URL\"], 9001)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Images Saved.\n"
     ]
    }
   ],
   "source": [
    "#Save Clusters to Local Directory\n",
    "obj_train.save_clusters(train_df, \"Users\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_0</th>\n",
       "      <th>Cluster_1</th>\n",
       "      <th>Cluster_2</th>\n",
       "      <th>Cluster_3</th>\n",
       "      <th>User_Handle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.139363e-01</td>\n",
       "      <td>2.119507e-01</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>2.788855e-01</td>\n",
       "      <td>sarrahdolly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.625207e-05</td>\n",
       "      <td>6.191084e-01</td>\n",
       "      <td>0.290787</td>\n",
       "      <td>9.007835e-02</td>\n",
       "      <td>alexchahine97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333209e-01</td>\n",
       "      <td>1.368621e-05</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.666524e-01</td>\n",
       "      <td>photographerarson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.973326e-26</td>\n",
       "      <td>1.636503e-27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.175125e-07</td>\n",
       "      <td>chelsea_xu620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cluster_0     Cluster_1  Cluster_2     Cluster_3        User_Handle\n",
       "0  2.139363e-01  2.119507e-01   0.295228  2.788855e-01        sarrahdolly\n",
       "1  2.625207e-05  6.191084e-01   0.290787  9.007835e-02      alexchahine97\n",
       "2  3.333209e-01  1.368621e-05   0.000013  6.666524e-01  photographerarson\n",
       "3  5.973326e-26  1.636503e-27   1.000000  2.175125e-07      chelsea_xu620"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get each user's presence in each cluster \n",
    "presence_df = obj_train.get_cluster_presence(train_df, k)\n",
    "display(presence_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_0</th>\n",
       "      <th>Cluster_1</th>\n",
       "      <th>Cluster_2</th>\n",
       "      <th>Cluster_3</th>\n",
       "      <th>User_Handle</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.139363e-01</td>\n",
       "      <td>2.119507e-01</td>\n",
       "      <td>0.295228</td>\n",
       "      <td>2.788855e-01</td>\n",
       "      <td>sarrahdolly</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.625207e-05</td>\n",
       "      <td>6.191084e-01</td>\n",
       "      <td>0.290787</td>\n",
       "      <td>9.007835e-02</td>\n",
       "      <td>alexchahine97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.333209e-01</td>\n",
       "      <td>1.368621e-05</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>6.666524e-01</td>\n",
       "      <td>photographerarson</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.973326e-26</td>\n",
       "      <td>1.636503e-27</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.175125e-07</td>\n",
       "      <td>chelsea_xu620</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cluster_0     Cluster_1  Cluster_2     Cluster_3        User_Handle  \\\n",
       "0  2.139363e-01  2.119507e-01   0.295228  2.788855e-01        sarrahdolly   \n",
       "1  2.625207e-05  6.191084e-01   0.290787  9.007835e-02      alexchahine97   \n",
       "2  3.333209e-01  1.368621e-05   0.000013  6.666524e-01  photographerarson   \n",
       "3  5.973326e-26  1.636503e-27   1.000000  2.175125e-07      chelsea_xu620   \n",
       "\n",
       "   Prediction  \n",
       "0           3  \n",
       "1           0  \n",
       "2           1  \n",
       "3           2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Fit Presence Model\n",
    "presence_df, model_users = obj_train.model_users_fit(presence_df, k, [\"User_Handle\"], 9001)\n",
    "display(presence_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved.\n",
      "Model Saved.\n"
     ]
    }
   ],
   "source": [
    "#Save Model\n",
    "obj_train.save_model(model_images, \"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/model_images.plk\")\n",
    "obj_train.save_model(model_users, \"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/model_users.plk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ClusteringTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define target path and create test object\n",
    "target_path = \"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/Images/Test/\"\n",
    "\n",
    "obj_test = ClusteringTest.Ranking(target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images loaded: 2\n"
     ]
    }
   ],
   "source": [
    "#Get Target Images\n",
    "obj_test.get_images_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get target dataframe\n",
    "target_df_cols = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "target_df = obj_test.convert_to_features(target_df_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "#Load Model\n",
    "model_images = obj_test.load_model(\"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/model_images.plk\")\n",
    "model_users = obj_test.load_model(\"/Users/kmotwani/Dropbox/Harvard/Capstone_EmpSirenuse/model_users.plk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Handle</th>\n",
       "      <th>URL</th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "      <th>Philosophical/White (0)</th>\n",
       "      <th>Nightlife/Black (1)</th>\n",
       "      <th>Colorful (2)</th>\n",
       "      <th>Random (3)</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input/Target</td>\n",
       "      <td>test1.jpg</td>\n",
       "      <td>168.21228300623292</td>\n",
       "      <td>50.559814473532846</td>\n",
       "      <td>177.0</td>\n",
       "      <td>152.20649178385617</td>\n",
       "      <td>55.545941306964636</td>\n",
       "      <td>157.0</td>\n",
       "      <td>133.1401432030083</td>\n",
       "      <td>59.39653323057275</td>\n",
       "      <td>132.0</td>\n",
       "      <td>29.697457889043424</td>\n",
       "      <td>157.3104023982487</td>\n",
       "      <td>124.26272193696765</td>\n",
       "      <td>5.966905e-02</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.935074</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Input/Target</td>\n",
       "      <td>12918414_1535355823435679_1454700275_n.jpg</td>\n",
       "      <td>69.02685501717532</td>\n",
       "      <td>64.38749628014699</td>\n",
       "      <td>47.0</td>\n",
       "      <td>101.4987613951645</td>\n",
       "      <td>70.35706785447088</td>\n",
       "      <td>92.0</td>\n",
       "      <td>125.40358287092086</td>\n",
       "      <td>56.03682228282825</td>\n",
       "      <td>122.0</td>\n",
       "      <td>46.59386766745937</td>\n",
       "      <td>111.95725933929968</td>\n",
       "      <td>133.13202668880595</td>\n",
       "      <td>1.990474e-42</td>\n",
       "      <td>0.996825</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_Handle                                         URL  \\\n",
       "0  Input/Target                                   test1.jpg   \n",
       "1  Input/Target  12918414_1535355823435679_1454700275_n.jpg   \n",
       "\n",
       "               R_Mean               R_STD  R_MED              G_Mean  \\\n",
       "0  168.21228300623292  50.559814473532846  177.0  152.20649178385617   \n",
       "1   69.02685501717532   64.38749628014699   47.0   101.4987613951645   \n",
       "\n",
       "                G_STD  G_MED              B_Mean              B_STD  B_MED  \\\n",
       "0  55.545941306964636  157.0   133.1401432030083  59.39653323057275  132.0   \n",
       "1   70.35706785447088   92.0  125.40358287092086  56.03682228282825  122.0   \n",
       "\n",
       "                Canny               ORB_X               ORB_Y  \\\n",
       "0  29.697457889043424   157.3104023982487  124.26272193696765   \n",
       "1   46.59386766745937  111.95725933929968  133.13202668880595   \n",
       "\n",
       "   Philosophical/White (0)  Nightlife/Black (1)  Colorful (2)  Random (3)  \\\n",
       "0             5.966905e-02             0.003429      0.935074    0.001828   \n",
       "1             1.990474e-42             0.996825      0.003119    0.000055   \n",
       "\n",
       "   Prediction  \n",
       "0           2  \n",
       "1           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get Prediction Dataframe\n",
    "target_df = obj_test.predict(target_df, model_images, k, [\"Philosophical/White\",\"Nightlife/Black\",\"Colorful\",\"Random\"], [\"User_Handle\",\"URL\"])\n",
    "display(target_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance to Cluster Dictionary:\n",
      "\n",
      " {'test1.jpg': [0.8975036955207851, 1.1795029253249076, 0.08826570922679301, 0.7439383335939207], '12918414_1535355823435679_1454700275_n.jpg': [0.48324614772849417, 1.2446274827103567, 1.4097627490039382, 0.9082236999348761]}\n"
     ]
    }
   ],
   "source": [
    "#Get Distance Dictionary\n",
    "dist_dict = obj_test.get_result(target_df, k, model_users)\n",
    "print(\"Distance to Cluster Dictionary:\\n\\n\", dist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
