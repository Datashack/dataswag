{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting RecSystemKM.py\n"
     ]
    }
   ],
   "source": [
    "%%file RecSystemKM.py\n",
    "\n",
    "import skimage\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class RecSystemKM:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, train_path, save_path):\n",
    "        self.train_path = train_path\n",
    "        self.save_path = save_path\n",
    "        \n",
    "    '''#Helper Function to get images from train path\n",
    "    def get_train_images(self, user_list):\n",
    "        list_users = user_list\n",
    "        self.train_imgs = {}\n",
    "        for i in list_users:\n",
    "            temp_path = self.train_path + i\n",
    "            for j in glob.glob(temp_path + '/*.jpg'):\n",
    "                file_name = j.replace(temp_path,'')[1:]\n",
    "                img = io.imread(j)\n",
    "                self.train_imgs[(i,file_name)] = img \n",
    "        print(\"Number of images loaded:\", len(self.train_imgs))'''\n",
    "\n",
    "    def get_train_images(self, train_path, user_list):\n",
    "        #list_users = user_list\n",
    "        self.train_imgs = {}\n",
    "        print(len(user_list))\n",
    "        for i in user_list:\n",
    "            file_name = i\n",
    "            img = io.imread(train_path+str(i)+'.jpg')\n",
    "            print(train_path+str(i)+'.jpg')\n",
    "            self.train_imgs[(i,file_name)] = img \n",
    "        print(\"Number of images loaded:\", len(self.train_imgs))\n",
    "\n",
    "    \n",
    "    #Helper function to convert image to d-dimension vector for each image and \n",
    "    #return dataframe of all images\n",
    "    def convert_to_features(self, columns):\n",
    "        features = []\n",
    "        for i in self.train_imgs.items():\n",
    "            r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "            g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "            b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "            canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "            try:\n",
    "                orb = cv2.ORB_create(100)\n",
    "                kp = orb.detect(i[1],None)\n",
    "                kp, des = orb.compute(i[1], kp)\n",
    "                orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "                orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "        df = pd.DataFrame(features, columns = columns)\n",
    "        return df\n",
    "    \n",
    "    def model_images_fit(self, df, k, extra_cols, rand_state):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "\n",
    "        #Implement Gaussian Mixture Model Algortihm \n",
    "        model = GaussianMixture(n_components=k, random_state=9001)\n",
    "\n",
    "        #Fit Model and Predict\n",
    "        model.fit(data)\n",
    "        y_pred = model.predict_proba(data)\n",
    "\n",
    "        #Add prediction to dataframe and return \n",
    "        for i in range(0,k+1):\n",
    "            if i==k:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = \"Prob_\" + str(i)\n",
    "            df[label] = y_pred[:,i]\n",
    "        return df, model\n",
    "    \n",
    "    def model_users_fit(self, df, k, extra_cols, rand_state):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "\n",
    "        #Implement K-Means Algortihm\n",
    "        model = KMeans(n_clusters=k, random_state=rand_state)\n",
    "\n",
    "        #Fit Model, Predict and Return\n",
    "        model.fit(data)\n",
    "        y_pred = model.predict(data)\n",
    "        df['Prediction'] = model.labels_\n",
    "        return df, model\n",
    "    \n",
    "    #Helper function to create folders for Image Clustering\n",
    "    def save_clusters(self, df, label):\n",
    "        self.save_path += label + \"/\"\n",
    "        for i in self.train_imgs.items():\n",
    "            temp_row = df[df[\"URL\"]==i[0][1]]\n",
    "            try:\n",
    "                name, pred_folder = i[0][1], str(temp_row['Prediction'].values[0])\n",
    "            except IndexError:\n",
    "                continue\n",
    "            temp_path = self.save_path + \"Cluster\" + pred_folder + \"/\"\n",
    "            if not os.path.exists(temp_path):\n",
    "                os.makedirs(temp_path)\n",
    "            io.imsave(temp_path+name, i[1])\n",
    "        print(\"All Images Saved.\")\n",
    "            \n",
    "    #Helper function to obtain percentage of Cluster Presence\n",
    "    def get_cluster_presence(self, df, k):\n",
    "        cluster_presence = []\n",
    "        for i in list(df['User_Handle'].unique()):\n",
    "            user_dict = {}\n",
    "            temp_df = df[df['User_Handle']==i]\n",
    "            post_count  =  len(temp_df)\n",
    "            user_dict['User_Handle'] = i\n",
    "            for j in range(0, k):\n",
    "                user_dict[\"Cluster_\"+str(j)] = sum(temp_df['Prob_'+str(j)])/post_count\n",
    "            cluster_presence.append(user_dict)\n",
    "        df_presence = pd.DataFrame(cluster_presence)\n",
    "        df_presence = df_presence.fillna(0)\n",
    "        return df_presence\n",
    "    \n",
    "    #Helper function to save model \n",
    "    def save_model(self, model, path):\n",
    "        joblib.dump(model, path) \n",
    "        print(\"Model Saved.\")\n",
    "\n",
    "\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "import cv2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "class Ranking:\n",
    "    \n",
    "    #Initialization\n",
    "    def __init__(self, target_path):\n",
    "        self.target_path = target_path\n",
    "\n",
    "    #Helper Function to get images from target path \n",
    "    def get_images_target(self):\n",
    "        #Get all Images of Users in the List\n",
    "        self.target_imgs = {}\n",
    "        for j in glob.glob(self.target_path + '/*.jpg'):\n",
    "            file_name = j.replace(self.target_path,'')[:]\n",
    "            img = io.imread(j)\n",
    "            self.target_imgs[(\"Input/Target\",file_name)] = img\n",
    "        print(\"Number of images loaded:\", len(self.target_imgs))\n",
    "    \n",
    "    #Helper function to load saved model\n",
    "    def load_model(self, path):\n",
    "        model = joblib.load(path)\n",
    "        print (\"Model loaded.\")\n",
    "        return model\n",
    "\n",
    "    #Helper function to convert image to d-dimension vector for each image and \n",
    "    #return dataframe of all images\n",
    "    def convert_to_features(self):\n",
    "        columns = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "\n",
    "        features = []\n",
    "        for i in self.target_imgs.items():\n",
    "            r_mean, r_std, r_med = np.mean(i[1][:,:,0].ravel()), np.std(i[1][:,:,0].ravel()), np.median(i[1][:,:,0].ravel())\n",
    "            g_mean, g_std, g_med  = np.mean(i[1][:,:,1].ravel()), np.std(i[1][:,:,1].ravel()), np.median(i[1][:,:,1].ravel())\n",
    "            b_mean, b_std, b_med  = np.mean(i[1][:,:,2].ravel()), np.std(i[1][:,:,2].ravel()), np.median(i[1][:,:,2].ravel())\n",
    "            canny = np.mean(np.ravel(cv2.Canny(cv2.cvtColor(i[1], cv2.COLOR_BGR2HSV),100,200,L2gradient = True)))\n",
    "            try:\n",
    "                orb = cv2.ORB_create(100)\n",
    "                kp = orb.detect(i[1],None)\n",
    "                kp, des = orb.compute(i[1], kp)\n",
    "                orb_centers = list(KMeans(1).fit([i.pt for i in kp]).cluster_centers_)\n",
    "                orbx1, orby1 = orb_centers[0][0]*255/np.shape(i[1])[0], orb_centers[0][1]*255/np.shape(i[1])[1]\n",
    "            except ValueError:\n",
    "                continue\n",
    "            features.append(np.array([i[0][0],i[0][1], r_mean, r_std, r_med, g_mean, g_std, g_med, b_mean, b_std, b_med, canny, orbx1, orby1]))\n",
    "        df = pd.DataFrame(features, columns = columns)\n",
    "        del df['User_Handle']\n",
    "        del df['URL']\n",
    "        return df\n",
    "\n",
    "    #Helper function to make prediction for target images using image model\n",
    "    def predict(self, df, model, k, cluster_names, extra_cols):\n",
    "        data = df.copy(deep=True)\n",
    "        \n",
    "        #Delete reference columns\n",
    "        for i in extra_cols:\n",
    "            del data[i]\n",
    "            \n",
    "        #Make Prediction\n",
    "        y_pred = model.predict_proba(data)\n",
    "        \n",
    "        #Add prediction to dataframe and return \n",
    "        for i in range(0,k+1):\n",
    "            if i==k:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = cluster_names[i] + \" (\" + str(i) + \")\"\n",
    "            df[label] = y_pred[:,i]\n",
    "        return df\n",
    "    \n",
    "    #Helper function to generate distance dictionary\n",
    "    def get_result(self, df, k, model):\n",
    "        final_dict = {}\n",
    "        for i in range(0,len(df)):\n",
    "            temp_file = df.iloc[i,1]\n",
    "            temp_dist = []\n",
    "            for j in range(0, k):\n",
    "                temp_dist.append(np.linalg.norm(df.iloc[i,14:14+k].astype(float)-model.cluster_centers_[j]))\n",
    "            final_dict[temp_file] = temp_dist\n",
    "        return final_dict\n",
    "    \n",
    "    # Add the prediction to the DF\n",
    "    def Predict_to_df(self, df, clustercount): \n",
    "        for i in range(0,cluster_count+1):\n",
    "            if i==cluster_count:\n",
    "                label = \"Prediction\"\n",
    "                df[label] = model.predict(data)\n",
    "                break\n",
    "            label = \"Prob_\" + str(i)\n",
    "        df[label] = y_pred[:,i]\n",
    "        \n",
    "        ### to get KL divrgences\n",
    "    def ranking(self,df, community): \n",
    "        \n",
    "        model = joblib.load('model_images.plk')\n",
    "        model_user.cluster_centers_\n",
    "        \n",
    "        \n",
    "        KL=[]\n",
    "        pic_no = []\n",
    "        community = []\n",
    "        # make a df with only the probs\n",
    "        filter_col = [col for col in df if col.startswith('Prob_')] \n",
    "        probabilities = df[filter_col]\n",
    "\n",
    "        for i in range(probabilities.shape[0]):\n",
    "\n",
    "            pic_dist = list(probabilities.iloc[i])\n",
    "\n",
    "            for v in enumerate(model_user.cluster_centers_):\n",
    "                clustercenter = (v[1])\n",
    "                KLdiv = stats.entropy(pk=clustercenter, qk=pic_dist)\n",
    "                KL.append(KLdiv)\n",
    "                pic_no.append(i)\n",
    "                community.append((v[0]))\n",
    "\n",
    "        KLdivergencedf = (pd.DataFrame({\"KL_score\":KL,\"picture_uploaded\": pic_no, \"community\":community}))\n",
    "        \n",
    "        sorted_df_by_community = (KLdivergencedf[KLdivergencedf['community']==2]).sort_values('KL_score').reset_index()\n",
    "        rankedpictures = (list(sorted_df_by_community.picture_number))\n",
    "        return(rankedpictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/python3/lib/python3.6/site-packages/skimage/viewer/__init__.py:6: UserWarning: Viewer requires Qt\n",
      "  warn('Viewer requires Qt')\n"
     ]
    }
   ],
   "source": [
    "import cv2 ## issues \n",
    "import skimage\n",
    "from skimage import io\n",
    "import pickle\n",
    "#define File-Path to Users Folder\n",
    "#import scikit-image\n",
    "import skimage\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import data\n",
    "from skimage import io\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import glob\n",
    "from skimage.viewer import ImageViewer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "%matplotlib inline\n",
    "\n",
    "#img = io.imread('~/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/11117159_1591691794419786_1496739027_n.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/1.jpg\n",
      "/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/2.jpg\n",
      "/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/3.jpg\n",
      "Number of images loaded: 3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import ClusteringTrainKM\n",
    "import RecSystemKM\n",
    "\n",
    "train_path = '/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/'\n",
    "save_path = '/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/'\n",
    "dest_img =  '/Users/kimia/Desktop/Capstone/imgcluster/Cluster4/'\n",
    "userlist= [1,2,3]\n",
    "#user list will be the picture number! \n",
    "\n",
    "#Helper Function to get images from train path\n",
    "c = RecSystemKM.RecSystemKM(train_path, save_path )\n",
    "c.get_train_images(train_path, user_list = ['1','2','3'])\n",
    "#Create Object\n",
    "\n",
    "train_df = c.convert_to_features()\n",
    "\n",
    "c.load_model()\n",
    "from sklearn.externals import joblib\n",
    "def cluster_uploaded_pics:\n",
    "    model = joblib.load('model_images.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_Handle</th>\n",
       "      <th>URL</th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>135.0129197103678</td>\n",
       "      <td>87.63115693479644</td>\n",
       "      <td>153.0</td>\n",
       "      <td>115.81277500106796</td>\n",
       "      <td>85.89295297982054</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.67071158528771</td>\n",
       "      <td>67.8223132968387</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.53199891067538</td>\n",
       "      <td>146.9227747599284</td>\n",
       "      <td>130.7175958633423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>182.62494660173437</td>\n",
       "      <td>71.07541423145153</td>\n",
       "      <td>214.0</td>\n",
       "      <td>114.09603945063864</td>\n",
       "      <td>61.1908801925312</td>\n",
       "      <td>116.0</td>\n",
       "      <td>59.164076850783886</td>\n",
       "      <td>49.102368231584244</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.82652505446623</td>\n",
       "      <td>158.0485753377279</td>\n",
       "      <td>124.39350624084474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>224.64943771626298</td>\n",
       "      <td>37.1131291445464</td>\n",
       "      <td>242.0</td>\n",
       "      <td>177.51967726088256</td>\n",
       "      <td>68.5927534247089</td>\n",
       "      <td>184.0</td>\n",
       "      <td>103.62004998077663</td>\n",
       "      <td>101.47531061170602</td>\n",
       "      <td>66.0</td>\n",
       "      <td>22.367919389978212</td>\n",
       "      <td>127.65924498240155</td>\n",
       "      <td>189.51394405364988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  User_Handle URL              R_Mean              R_STD  R_MED  \\\n",
       "0           1   1   135.0129197103678  87.63115693479644  153.0   \n",
       "1           2   2  182.62494660173437  71.07541423145153  214.0   \n",
       "2           3   3  224.64943771626298   37.1131291445464  242.0   \n",
       "\n",
       "               G_Mean              G_STD  G_MED              B_Mean  \\\n",
       "0  115.81277500106796  85.89295297982054  109.0   58.67071158528771   \n",
       "1  114.09603945063864   61.1908801925312  116.0  59.164076850783886   \n",
       "2  177.51967726088256   68.5927534247089  184.0  103.62004998077663   \n",
       "\n",
       "                B_STD B_MED               Canny               ORB_X  \\\n",
       "0    67.8223132968387  33.0   22.53199891067538   146.9227747599284   \n",
       "1  49.102368231584244  42.0   15.82652505446623   158.0485753377279   \n",
       "2  101.47531061170602  66.0  22.367919389978212  127.65924498240155   \n",
       "\n",
       "                ORB_Y  \n",
       "0   130.7175958633423  \n",
       "1  124.39350624084474  \n",
       "2  189.51394405364988  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Get train dataframe\n",
    "train_df_cols = [\"User_Handle\",\"URL\",\"R_Mean\", \"R_STD\", \"R_MED\", \"G_Mean\", \"G_STD\", \n",
    "                \"G_MED\", \"B_Mean\", \"B_STD\", \"B_MED\", \"Canny\", \"ORB_X\", \"ORB_Y\"]\n",
    "\n",
    "train_df = c.convert_to_features(train_df_cols)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df\n",
    "del df['User_Handle']\n",
    "del df['URL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.externals import joblib\n",
    "def cluster_uploaded_pics:\n",
    "    model = joblib.load('model_images.plk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.48407625e-06, 1.73430122e-02, 2.90112949e-02, 3.71834975e-02,\n",
       "        9.16452711e-01],\n",
       "       [4.49303540e-02, 8.15995366e-01, 7.48122668e-02, 2.66606310e-04,\n",
       "        6.39954070e-02],\n",
       "       [2.39535693e-01, 3.06436341e-01, 2.56485322e-01, 8.08224675e-02,\n",
       "        1.16720177e-01],\n",
       "       [0.00000000e+00, 6.35781539e-10, 0.00000000e+00, 9.99971800e-01,\n",
       "        2.81989199e-05],\n",
       "       [8.88222290e-02, 1.17511792e-01, 7.88032046e-01, 9.71445147e-17,\n",
       "        5.63393249e-03]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_user = joblib.load('model_users.plk')\n",
    "\n",
    "model_user.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Dataset\n",
    "data = df.copy(deep=True)\n",
    "#model.fit(data)\n",
    "y_pred = model.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def Predict_to_df( df, clustercount): \n",
    "    for i in range(0,cluster_count+1):\n",
    "        if i==cluster_count:\n",
    "            label = \"Prediction\"\n",
    "            df[label] = model.predict(data)\n",
    "            break\n",
    "        label = \"Prob_\" + str(i)\n",
    "        df[label] = y_pred[:,i]\"\"\"\n",
    "#Added above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"cluster_count = 5\n",
    "#Add prediction to dataframe     \n",
    "for i in range(0,cluster_count+1):\n",
    "    if i==cluster_count:\n",
    "        label = \"Prediction\"\n",
    "        df[label] = model.predict(data)\n",
    "        break\n",
    "    label = \"Prob_\" + str(i)\n",
    "    df[label] = y_pred[:,i]\n",
    "    \n",
    "\n",
    "display(df.head())\"\"\"\n",
    "Predict_to_df(df, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R_Mean</th>\n",
       "      <th>R_STD</th>\n",
       "      <th>R_MED</th>\n",
       "      <th>G_Mean</th>\n",
       "      <th>G_STD</th>\n",
       "      <th>G_MED</th>\n",
       "      <th>B_Mean</th>\n",
       "      <th>B_STD</th>\n",
       "      <th>B_MED</th>\n",
       "      <th>Canny</th>\n",
       "      <th>ORB_X</th>\n",
       "      <th>ORB_Y</th>\n",
       "      <th>Prob_0</th>\n",
       "      <th>Prob_1</th>\n",
       "      <th>Prob_2</th>\n",
       "      <th>Prob_3</th>\n",
       "      <th>Prob_4</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0129197103678</td>\n",
       "      <td>87.63115693479644</td>\n",
       "      <td>153.0</td>\n",
       "      <td>115.81277500106796</td>\n",
       "      <td>85.89295297982054</td>\n",
       "      <td>109.0</td>\n",
       "      <td>58.67071158528771</td>\n",
       "      <td>67.8223132968387</td>\n",
       "      <td>33.0</td>\n",
       "      <td>22.53199891067538</td>\n",
       "      <td>146.9227747599284</td>\n",
       "      <td>130.7175958633423</td>\n",
       "      <td>5.078126e-18</td>\n",
       "      <td>1.441767e-08</td>\n",
       "      <td>3.988279e-01</td>\n",
       "      <td>2.107406e-20</td>\n",
       "      <td>0.601172</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>182.62494660173437</td>\n",
       "      <td>71.07541423145153</td>\n",
       "      <td>214.0</td>\n",
       "      <td>114.09603945063864</td>\n",
       "      <td>61.1908801925312</td>\n",
       "      <td>116.0</td>\n",
       "      <td>59.164076850783886</td>\n",
       "      <td>49.102368231584244</td>\n",
       "      <td>42.0</td>\n",
       "      <td>15.82652505446623</td>\n",
       "      <td>158.0485753377279</td>\n",
       "      <td>124.39350624084474</td>\n",
       "      <td>3.710005e-15</td>\n",
       "      <td>4.197616e-06</td>\n",
       "      <td>8.920294e-01</td>\n",
       "      <td>1.499184e-14</td>\n",
       "      <td>0.107966</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224.64943771626298</td>\n",
       "      <td>37.1131291445464</td>\n",
       "      <td>242.0</td>\n",
       "      <td>177.51967726088256</td>\n",
       "      <td>68.5927534247089</td>\n",
       "      <td>184.0</td>\n",
       "      <td>103.62004998077663</td>\n",
       "      <td>101.47531061170602</td>\n",
       "      <td>66.0</td>\n",
       "      <td>22.367919389978212</td>\n",
       "      <td>127.65924498240155</td>\n",
       "      <td>189.51394405364988</td>\n",
       "      <td>4.270073e-62</td>\n",
       "      <td>4.177991e-04</td>\n",
       "      <td>9.591860e-07</td>\n",
       "      <td>1.620037e-87</td>\n",
       "      <td>0.999581</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               R_Mean              R_STD  R_MED              G_Mean  \\\n",
       "0   135.0129197103678  87.63115693479644  153.0  115.81277500106796   \n",
       "1  182.62494660173437  71.07541423145153  214.0  114.09603945063864   \n",
       "2  224.64943771626298   37.1131291445464  242.0  177.51967726088256   \n",
       "\n",
       "               G_STD  G_MED              B_Mean               B_STD B_MED  \\\n",
       "0  85.89295297982054  109.0   58.67071158528771    67.8223132968387  33.0   \n",
       "1   61.1908801925312  116.0  59.164076850783886  49.102368231584244  42.0   \n",
       "2   68.5927534247089  184.0  103.62004998077663  101.47531061170602  66.0   \n",
       "\n",
       "                Canny               ORB_X               ORB_Y        Prob_0  \\\n",
       "0   22.53199891067538   146.9227747599284   130.7175958633423  5.078126e-18   \n",
       "1   15.82652505446623   158.0485753377279  124.39350624084474  3.710005e-15   \n",
       "2  22.367919389978212  127.65924498240155  189.51394405364988  4.270073e-62   \n",
       "\n",
       "         Prob_1        Prob_2        Prob_3    Prob_4  Prediction  \n",
       "0  1.441767e-08  3.988279e-01  2.107406e-20  0.601172           4  \n",
       "1  4.197616e-06  8.920294e-01  1.499184e-14  0.107966           2  \n",
       "2  4.177991e-04  9.591860e-07  1.620037e-87  0.999581           4  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# targeting PEOPLE\n",
    "# distirbut rep img, compare to dist repre person. \n",
    "## distribution over images, same cluster of images. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now need to compare it to the files.. So is 'presence DF' the communities? Like the centroid?\n",
    "\n",
    "## or...should I take a summary statistic of each cluster across all and comapre to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imgdf = pd.read_csv('/Users/kimia/Desktop/Capstone/imgcluster/ImageDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Presdf = pd.read_csv('/Users/kimia/Desktop/Capstone/imgcluster/PresenceDF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Treating Presdf as the centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## KL Divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1156842395594326\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "row0_vaso = ([9.48407625e-06, 1.73430122e-02, 2.90112949e-02, 3.71834975e-02,\n",
    "        9.16452711e-01])\n",
    "myown4 = [5.078126e-18, 1.441767e-08, 3.988279e-01, 2.107406e-20, 0.601172]\n",
    "print(stats.entropy(pk=row0_vaso, qk=myown4))\n",
    "\n",
    "myown2 = [3.710005e-15, 4.197616e-06, 8.920294e-01, 1.499184e-14, 0.107966]\n",
    "#print(stats.entropy(pk=row0_vaso, qk=myown2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rank(community): \n",
    "    sorted_df_by_community = (fdf[fdf['community']==2]).sort_values('KL_score').reset_index()\n",
    "print(list(sorted_df_by_community.picture_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "fdf = calc_KL_divergence(df)\n",
    "sorted_df_by_community = (fdf[fdf['community']==2]).sort_values('KL_score').reset_index()\n",
    "print(list(sorted_df_by_community.picture_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KL</th>\n",
       "      <th>com</th>\n",
       "      <th>pic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.115684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.957836</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.520507</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.304657</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.702374</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.066426</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.077834</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.107254</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.830112</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.825286</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.594028</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.110483</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>54.430906</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>199.836495</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>23.701988</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            KL  com  pic\n",
       "0     2.115684    0    0\n",
       "1    15.957836    1    0\n",
       "2    17.520507    2    0\n",
       "3    45.304657    3    0\n",
       "4     5.702374    4    0\n",
       "5     3.066426    0    1\n",
       "6    11.077834    1    1\n",
       "7    13.107254    2    1\n",
       "8    31.830112    3    1\n",
       "9     3.825286    4    1\n",
       "10    7.594028    0    2\n",
       "11   13.110483    1    2\n",
       "12   54.430906    2    2\n",
       "13  199.836495    3    2\n",
       "14   23.701988    4    2"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KL=[]\n",
    "pic_no = []\n",
    "community = []\n",
    "for i in range(s.shape[0]):\n",
    " \n",
    "    pic_dist = list(s.iloc[i])\n",
    "    #print(pic_dist)\n",
    "    for v in enumerate(model_user.cluster_centers_):\n",
    "        clustercenter = (v[1])\n",
    "        KLdiv = stats.entropy(pk=clustercenter, qk=pic_dist)\n",
    "        KL.append(KLdiv)\n",
    "        pic_no.append(i)\n",
    "        community.append((v[0]))\n",
    "        \n",
    "test = (pd.DataFrame({\"KL\":KL,\"pic\": pic_no, \"com\":community}))#.transpose()#.rename(columns=['kl', 'nnu', 'comm'])\"\"\"\"\n",
    "#pd.DataFrame(test, columns = ['hi', '4', 'hii'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23953569, 0.30643634, 0.25648532, 0.08082247, 0.11672018])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_user.cluster_centers_[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>(4, [0.08882222898447056, 0.11751179212073659,...</td>\n",
       "      <td>23.702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1       2\n",
       "0  2  (4, [0.08882222898447056, 0.11751179212073659,...  23.702"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cols = ['picture','communitycluster', 'score']\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11568423826652\n",
      "15.957836424717797\n",
      "17.520506566471457\n",
      "45.304657081334575\n",
      "5.702374000473236\n"
     ]
    }
   ],
   "source": [
    "## This is the score depending on which cluster you'd like to optimize for \n",
    "for i in range(model_user.n_clusters):\n",
    "    user_centroid = model_user.cluster_centers_[i]\n",
    "    print(stats.entropy(pk=user_centroid, qk=myown4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rank from lowest to highest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Know user type, are imagines relev to user type? \n",
    "# Math and qualit analysis \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two groups of images, for two types of users --> 3\n",
    "Know how the ranking should \n",
    "# selfie person --> dont target them with landscape\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#People to test analysis on: \n",
    "# Go grab painters on IG, illustrators.\n",
    "# All their artwork.\n",
    "\n",
    "# Selfie people --> Beauty. Ask Ale and Andreea --> cosmetics. \n",
    "\n",
    "# retrain the model. \n",
    "# see if ranking, does exactly this. \n",
    "\n",
    "# https://www.instagram.com/explore/tags/mountaineering/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# next steps, engagement \n",
    "# predicted engagement value --> how to combine scores (KL, engagement)\n",
    "# Predict number of shares, likes, comment. \n",
    "# predictive model. , likes, shares, etc. image with features. image --> engagement. \n",
    "# could be lienar, couild be else. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
