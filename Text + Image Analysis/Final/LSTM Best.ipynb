{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Model\n",
    "import pandas as pd\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "import json\n",
    "import gensim\n",
    "import glob\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "import re\n",
    "from keras import utils\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Google's pre-trained Word2Vec model.\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format('google_w2vec.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 3000000\n",
      "<class 'dict'>\n",
      "Vector Size: 300\n"
     ]
    }
   ],
   "source": [
    "vecsize = word_vectors.vector_size\n",
    "print('Vocabulary Size:', len(word_vectors.vocab))\n",
    "print(type(word_vectors.vocab))\n",
    "print('Vector Size:', vecsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define File-Path to Users Folder\n",
    "folder_list = ['#foodporn',\"#nightlife\",\"#cosmetics\",\"#rockclimbing\"]\n",
    "image_path = \"/Users/kmotwani/Desktop/Me/Education/Courses/Capstone Project/Insta Images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#foodporn \n",
      "\n",
      "#nightlife \n",
      "\n",
      "#cosmetics \n",
      "\n",
      "#rockclimbing \n",
      "\n",
      "Number of images loaded: 32595\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>File</th>\n",
       "      <th>Image</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...Siempre quise ser grande para poder comerme...</td>\n",
       "      <td>2018-04-08_21-17-49_UTC.jpg</td>\n",
       "      <td>[[[82, 68, 59], [88, 85, 96], [128, 104, 80], ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lonche de Panela By @mojito.restobar . . . #va...</td>\n",
       "      <td>2018-04-08_21-36-39_UTC.jpg</td>\n",
       "      <td>[[[165, 158, 199], [162, 155, 196], [167, 159,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brunching with friends is the best way to spen...</td>\n",
       "      <td>2018-04-08_20-19-50_UTC.jpg</td>\n",
       "      <td>[[[61, 51, 49], [48, 37, 31], [153, 149, 166],...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obsessed with their little stoves. Ordered the...</td>\n",
       "      <td>2018-02-02_15-27-17_UTC.jpg</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hoje para o jantar foram dois ovos, em cima de...</td>\n",
       "      <td>2018-04-08_21-36-29_UTC.jpg</td>\n",
       "      <td>[[[147, 163, 160], [152, 163, 155], [131, 101,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption  \\\n",
       "0  ...Siempre quise ser grande para poder comerme...   \n",
       "1  Lonche de Panela By @mojito.restobar . . . #va...   \n",
       "2  Brunching with friends is the best way to spen...   \n",
       "3  Obsessed with their little stoves. Ordered the...   \n",
       "4  Hoje para o jantar foram dois ovos, em cima de...   \n",
       "\n",
       "                          File  \\\n",
       "0  2018-04-08_21-17-49_UTC.jpg   \n",
       "1  2018-04-08_21-36-39_UTC.jpg   \n",
       "2  2018-04-08_20-19-50_UTC.jpg   \n",
       "3  2018-02-02_15-27-17_UTC.jpg   \n",
       "4  2018-04-08_21-36-29_UTC.jpg   \n",
       "\n",
       "                                               Image  Response  \n",
       "0  [[[82, 68, 59], [88, 85, 96], [128, 104, 80], ...         0  \n",
       "1  [[[165, 158, 199], [162, 155, 196], [167, 159,...         0  \n",
       "2  [[[61, 51, 49], [48, 37, 31], [153, 149, 166],...         0  \n",
       "3  [[[255, 255, 255], [255, 255, 255], [255, 255,...         0  \n",
       "4  [[[147, 163, 160], [152, 163, 155], [131, 101,...         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Helper Function to get images from path\n",
    "def get_df(path, list_input, thresh):\n",
    "    final_list = []\n",
    "    for ind, i in enumerate(list_input):\n",
    "        temp_path = path + i\n",
    "        print(i,\"\\n\")\n",
    "        count = 0\n",
    "        for j in glob.glob(temp_path + '/*.jpg'):\n",
    "            temp_dict = {}\n",
    "            file_name = j.replace(temp_path,'')[1:]\n",
    "            img = image.load_img(j, target_size=(128, 128))\n",
    "            try:\n",
    "                with open(temp_path+\"/\"+file_name[:-4]+'.txt', encoding=\"utf-8\") as f:\n",
    "                    content = f.readlines()\n",
    "                    caption = ' '.join([x.strip() for x in content])\n",
    "            except FileNotFoundError:\n",
    "                continue\n",
    "            temp_dict['File'], temp_dict['Response'] = file_name, int(ind)\n",
    "            temp_dict['Image'], temp_dict['Caption'] = np.array(img), caption\n",
    "            final_list.append(temp_dict)\n",
    "            count += 1\n",
    "            if count==thresh:\n",
    "                break\n",
    "    return pd.DataFrame(final_list) \n",
    "\n",
    "\n",
    "#Get Images from User List and Path\n",
    "df = get_df(image_path, folder_list, 9000)\n",
    "print(\"Number of images loaded:\", len(df))\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>File</th>\n",
       "      <th>Image</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>...Siempre quise ser grande para poder comerme...</td>\n",
       "      <td>2018-04-08_21-17-49_UTC.jpg</td>\n",
       "      <td>[[[82, 68, 59], [88, 85, 96], [128, 104, 80], ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lonche de Panela By @mojito.restobar . . . #va...</td>\n",
       "      <td>2018-04-08_21-36-39_UTC.jpg</td>\n",
       "      <td>[[[165, 158, 199], [162, 155, 196], [167, 159,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brunching with friends is the best way to spen...</td>\n",
       "      <td>2018-04-08_20-19-50_UTC.jpg</td>\n",
       "      <td>[[[61, 51, 49], [48, 37, 31], [153, 149, 166],...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Obsessed with their little stoves. Ordered the...</td>\n",
       "      <td>2018-02-02_15-27-17_UTC.jpg</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hoje para o jantar foram dois ovos, em cima de...</td>\n",
       "      <td>2018-04-08_21-36-29_UTC.jpg</td>\n",
       "      <td>[[[147, 163, 160], [152, 163, 155], [131, 101,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption  \\\n",
       "0  ...Siempre quise ser grande para poder comerme...   \n",
       "1  Lonche de Panela By @mojito.restobar . . . #va...   \n",
       "2  Brunching with friends is the best way to spen...   \n",
       "3  Obsessed with their little stoves. Ordered the...   \n",
       "4  Hoje para o jantar foram dois ovos, em cima de...   \n",
       "\n",
       "                          File  \\\n",
       "0  2018-04-08_21-17-49_UTC.jpg   \n",
       "1  2018-04-08_21-36-39_UTC.jpg   \n",
       "2  2018-04-08_20-19-50_UTC.jpg   \n",
       "3  2018-02-02_15-27-17_UTC.jpg   \n",
       "4  2018-04-08_21-36-29_UTC.jpg   \n",
       "\n",
       "                                               Image  Response  \n",
       "0  [[[82, 68, 59], [88, 85, 96], [128, 104, 80], ...         0  \n",
       "1  [[[165, 158, 199], [162, 155, 196], [167, 159,...         0  \n",
       "2  [[[61, 51, 49], [48, 37, 31], [153, 149, 166],...         0  \n",
       "3  [[[255, 255, 255], [255, 255, 255], [255, 255,...         0  \n",
       "4  [[[147, 163, 160], [152, 163, 155], [131, 101,...         0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Remove Hashtags\n",
    "df['Caption'] = df['Caption'].str.replace('#foodporn','', case=False)\n",
    "df['Caption'] = df['Caption'].str.replace('#rockclimbing','', case=False)\n",
    "df['Caption'] = df['Caption'].str.replace('#nightlife','', case=False)\n",
    "df['Caption'] = df['Caption'].str.replace('#cosmetics','', case=False)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Caption</th>\n",
       "      <th>File</th>\n",
       "      <th>Image</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Training Insight 1! The slightly obvious, but ...</td>\n",
       "      <td>2018-04-07_18-00-21_UTC.jpg</td>\n",
       "      <td>[[[141, 129, 115], [136, 112, 110], [108, 86, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Repost from @tyan_bf ・・・ Dijual botol bekas k...</td>\n",
       "      <td>2018-04-08_11-06-47_UTC.jpg</td>\n",
       "      <td>[[[59, 103, 148], [56, 100, 145], [54, 98, 143...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Le fond du coeur est plus loin que le bout du ...</td>\n",
       "      <td>2017-07-08_07-04-50_UTC.jpg</td>\n",
       "      <td>[[[255, 255, 255], [255, 255, 255], [255, 255,...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Testimoni produk Drk yg menjadi kegilaan ramai...</td>\n",
       "      <td>2018-04-08_16-38-04_UTC.jpg</td>\n",
       "      <td>[[[211, 211, 211], [211, 211, 211], [211, 211,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>. 一緒に過ごした時間 楽しい会話 まるで友達のように . そんな時間の積み重ねが 大人の時...</td>\n",
       "      <td>2018-04-08_12-17-45_UTC.jpg</td>\n",
       "      <td>[[[234, 247, 255], [234, 247, 255], [234, 247,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Caption  \\\n",
       "0  Training Insight 1! The slightly obvious, but ...   \n",
       "1  #Repost from @tyan_bf ・・・ Dijual botol bekas k...   \n",
       "2  Le fond du coeur est plus loin que le bout du ...   \n",
       "3  Testimoni produk Drk yg menjadi kegilaan ramai...   \n",
       "4  . 一緒に過ごした時間 楽しい会話 まるで友達のように . そんな時間の積み重ねが 大人の時...   \n",
       "\n",
       "                          File  \\\n",
       "0  2018-04-07_18-00-21_UTC.jpg   \n",
       "1  2018-04-08_11-06-47_UTC.jpg   \n",
       "2  2017-07-08_07-04-50_UTC.jpg   \n",
       "3  2018-04-08_16-38-04_UTC.jpg   \n",
       "4  2018-04-08_12-17-45_UTC.jpg   \n",
       "\n",
       "                                               Image  Response  \n",
       "0  [[[141, 129, 115], [136, 112, 110], [108, 86, ...         3  \n",
       "1  [[[59, 103, 148], [56, 100, 145], [54, 98, 143...         1  \n",
       "2  [[[255, 255, 255], [255, 255, 255], [255, 255,...         3  \n",
       "3  [[[211, 211, 211], [211, 211, 211], [211, 211,...         2  \n",
       "4  [[[234, 247, 255], [234, 247, 255], [234, 247,...         2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Split data into Train and Test set\n",
    "use_df = df.sample(frac=1).reset_index(drop=True)\n",
    "display(use_df.head())\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(use_df)) < 0.7\n",
    "total_data_train = use_df[msk]\n",
    "total_data_test = use_df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to get text vector\n",
    "def get_vector(x, limit):\n",
    "    sequence, count = np.zeros((limit, 300), dtype=float), 0\n",
    "    x = re.sub(r'[^\\w\\s]','',x)\n",
    "    for word in x.split():\n",
    "        if word in word_vectors.vocab:\n",
    "            if count<limit: \n",
    "                sequence[count] = word_vectors.get_vector(word)\n",
    "        count += 1\n",
    "    return sequence\n",
    "\n",
    "#Define Train and Test Dataframes\n",
    "x_train, x_test = [], []\n",
    "total_data_train['Caption'].astype(str).apply(lambda x: x_train.append(get_vector(x, 100)))\n",
    "total_data_test['Caption'].astype(str).apply(lambda x: x_test.append(get_vector(x, 100)))\n",
    "y_train = utils.to_categorical(total_data_train['Response'].as_matrix(), num_classes=4)\n",
    "y_test = utils.to_categorical(total_data_test['Response'].as_matrix(), num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Change X,Y to Numpy Arrays\n",
    "x_train = np.array(x_train)\n",
    "x_test = np.array(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to create CNN Model for Image Classification\n",
    "def createModel(size, classes):\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.LSTM(size, input_shape=(100, 300), return_sequences=False))\n",
    "    model.add(Dense(classes, activation='tanh'))  \n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "#Helper function to run model and save intermediate weights\n",
    "def run_model(model, x_train, y_train, x_test, y_test, batch_size, epochs):\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "    filepath=\"KRM_LSTM_New_weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "    check = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max', period = 5)\n",
    "    callbacks_list = [check]\n",
    "    history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, \n",
    "                       validation_data=(x_test, y_test), callbacks=callbacks_list)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 64)                93440     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 93,700\n",
      "Trainable params: 93,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 22979 samples, validate on 9616 samples\n",
      "Epoch 1/50\n",
      "22979/22979 [==============================] - 58s 3ms/step - loss: 0.1991 - acc: 0.2824 - val_loss: 0.1841 - val_acc: 0.3001\n",
      "Epoch 2/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.1829 - acc: 0.3059 - val_loss: 0.1819 - val_acc: 0.3143\n",
      "Epoch 3/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.1519 - acc: 0.4625 - val_loss: 0.1370 - val_acc: 0.5203\n",
      "Epoch 4/50\n",
      "22979/22979 [==============================] - 50s 2ms/step - loss: 0.1111 - acc: 0.6520 - val_loss: 0.0971 - val_acc: 0.7080\n",
      "Epoch 5/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0970 - acc: 0.7027 - val_loss: 0.0918 - val_acc: 0.7117\n",
      "\n",
      "Epoch 00005: val_acc improved from -inf to 0.71173, saving model to KRM_LSTM_New_weights-05-0.71.hdf5\n",
      "Epoch 6/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0778 - acc: 0.7831 - val_loss: 0.0693 - val_acc: 0.8057\n",
      "Epoch 7/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0580 - acc: 0.8369 - val_loss: 0.0558 - val_acc: 0.8386\n",
      "Epoch 8/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0529 - acc: 0.8485 - val_loss: 0.0524 - val_acc: 0.8507\n",
      "Epoch 9/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0511 - acc: 0.8557 - val_loss: 0.0545 - val_acc: 0.8462\n",
      "Epoch 10/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0497 - acc: 0.8580 - val_loss: 0.0521 - val_acc: 0.8495\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.71173 to 0.84952, saving model to KRM_LSTM_New_weights-10-0.85.hdf5\n",
      "Epoch 11/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0476 - acc: 0.8657 - val_loss: 0.0510 - val_acc: 0.8524\n",
      "Epoch 12/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0473 - acc: 0.8671 - val_loss: 0.0508 - val_acc: 0.8613\n",
      "Epoch 13/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0462 - acc: 0.8688 - val_loss: 0.0501 - val_acc: 0.8600\n",
      "Epoch 14/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0456 - acc: 0.8706 - val_loss: 0.0501 - val_acc: 0.8602\n",
      "Epoch 15/50\n",
      "22979/22979 [==============================] - 57s 2ms/step - loss: 0.0456 - acc: 0.8701 - val_loss: 0.0502 - val_acc: 0.8623\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.84952 to 0.86231, saving model to KRM_LSTM_New_weights-15-0.86.hdf5\n",
      "Epoch 16/50\n",
      "22979/22979 [==============================] - 54s 2ms/step - loss: 0.0439 - acc: 0.8751 - val_loss: 0.0489 - val_acc: 0.8610\n",
      "Epoch 17/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0435 - acc: 0.8771 - val_loss: 0.0523 - val_acc: 0.8552\n",
      "Epoch 18/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0436 - acc: 0.8779 - val_loss: 0.0495 - val_acc: 0.8629\n",
      "Epoch 19/50\n",
      "22979/22979 [==============================] - 50s 2ms/step - loss: 0.0434 - acc: 0.8775 - val_loss: 0.0501 - val_acc: 0.8664\n",
      "Epoch 20/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0422 - acc: 0.8815 - val_loss: 0.0498 - val_acc: 0.8624\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.86231 to 0.86242, saving model to KRM_LSTM_New_weights-20-0.86.hdf5\n",
      "Epoch 21/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0412 - acc: 0.8827 - val_loss: 0.0496 - val_acc: 0.8645\n",
      "Epoch 22/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0412 - acc: 0.8853 - val_loss: 0.0494 - val_acc: 0.8642\n",
      "Epoch 23/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0401 - acc: 0.8884 - val_loss: 0.0496 - val_acc: 0.8637\n",
      "Epoch 24/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0395 - acc: 0.8882 - val_loss: 0.0483 - val_acc: 0.8675\n",
      "Epoch 25/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0388 - acc: 0.8909 - val_loss: 0.0506 - val_acc: 0.8616\n",
      "\n",
      "Epoch 00025: val_acc did not improve\n",
      "Epoch 26/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0400 - acc: 0.8884 - val_loss: 0.0485 - val_acc: 0.8666\n",
      "Epoch 27/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0396 - acc: 0.8896 - val_loss: 0.0502 - val_acc: 0.8609\n",
      "Epoch 28/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0381 - acc: 0.8947 - val_loss: 0.0483 - val_acc: 0.8642\n",
      "Epoch 29/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0379 - acc: 0.8936 - val_loss: 0.0485 - val_acc: 0.8634\n",
      "Epoch 30/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0375 - acc: 0.8947 - val_loss: 0.0483 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00030: val_acc improved from 0.86242 to 0.86658, saving model to KRM_LSTM_New_weights-30-0.87.hdf5\n",
      "Epoch 31/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0372 - acc: 0.8953 - val_loss: 0.0492 - val_acc: 0.8634\n",
      "Epoch 32/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0394 - acc: 0.8902 - val_loss: 0.0502 - val_acc: 0.8626\n",
      "Epoch 33/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0388 - acc: 0.8907 - val_loss: 0.0505 - val_acc: 0.8656\n",
      "Epoch 34/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0370 - acc: 0.8959 - val_loss: 0.0489 - val_acc: 0.8661\n",
      "Epoch 35/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0352 - acc: 0.9021 - val_loss: 0.0485 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00035: val_acc did not improve\n",
      "Epoch 36/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0356 - acc: 0.9007 - val_loss: 0.0498 - val_acc: 0.8682\n",
      "Epoch 37/50\n",
      "22979/22979 [==============================] - 55s 2ms/step - loss: 0.0351 - acc: 0.9033 - val_loss: 0.0500 - val_acc: 0.8683\n",
      "Epoch 38/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0350 - acc: 0.9028 - val_loss: 0.0487 - val_acc: 0.8688\n",
      "Epoch 39/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0344 - acc: 0.9037 - val_loss: 0.0495 - val_acc: 0.8669\n",
      "Epoch 40/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0340 - acc: 0.9050 - val_loss: 0.0496 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00040: val_acc improved from 0.86658 to 0.86699, saving model to KRM_LSTM_New_weights-40-0.87.hdf5\n",
      "Epoch 41/50\n",
      "22979/22979 [==============================] - 53s 2ms/step - loss: 0.0446 - acc: 0.8741 - val_loss: 0.0815 - val_acc: 0.7626\n",
      "Epoch 42/50\n",
      "22979/22979 [==============================] - 52s 2ms/step - loss: 0.0520 - acc: 0.8579 - val_loss: 0.0519 - val_acc: 0.8610\n",
      "Epoch 43/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0389 - acc: 0.8935 - val_loss: 0.0499 - val_acc: 0.8629\n",
      "Epoch 44/50\n",
      "22979/22979 [==============================] - 50s 2ms/step - loss: 0.0374 - acc: 0.8967 - val_loss: 0.0500 - val_acc: 0.8674\n",
      "Epoch 45/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0360 - acc: 0.9003 - val_loss: 0.0493 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00045: val_acc improved from 0.86699 to 0.86751, saving model to KRM_LSTM_New_weights-45-0.87.hdf5\n",
      "Epoch 46/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0352 - acc: 0.9019 - val_loss: 0.0484 - val_acc: 0.8658\n",
      "Epoch 47/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0339 - acc: 0.9062 - val_loss: 0.0498 - val_acc: 0.8674\n",
      "Epoch 48/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0328 - acc: 0.9088 - val_loss: 0.0499 - val_acc: 0.8686\n",
      "Epoch 49/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0324 - acc: 0.9102 - val_loss: 0.0488 - val_acc: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50\n",
      "22979/22979 [==============================] - 51s 2ms/step - loss: 0.0323 - acc: 0.9095 - val_loss: 0.0493 - val_acc: 0.8637\n",
      "\n",
      "Epoch 00050: val_acc did not improve\n"
     ]
    }
   ],
   "source": [
    "#Create and Fit Model\n",
    "model = createModel(64, 4)\n",
    "model, history = run_model(model, x_train, y_train, x_test, y_test, batch_size=512, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
